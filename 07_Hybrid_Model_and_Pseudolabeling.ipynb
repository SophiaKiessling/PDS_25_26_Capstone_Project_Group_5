{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef0e4928",
   "metadata": {},
   "source": [
    "# LINKEDIN JOB CLASSIFICATION - HYBRID MODEL\n",
    "## Seniority & Department Prediction mit Ensemble Pseudo-Labeling & Hybrid ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd0ca3",
   "metadata": {},
   "source": [
    "## 1 IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "536ec4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492181f",
   "metadata": {},
   "source": [
    "## 2 LOAD DATA & TRAIN-TEST SPLIT\n",
    "Load the CSV Files and performe a 80:20 Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3c6ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Seniority: 9428 Eintr√§ge\n",
      "   Department: 10145 Eintr√§ge\n",
      "\n",
      " Train-Test Split:\n",
      "   Seniority - Train: 7542, Test: 1886\n",
      "   Department - Train: 8116, Test: 2029\n"
     ]
    }
   ],
   "source": [
    "# Load CSV Training Data\n",
    "df_seniority = pd.read_csv('seniority-v2.csv')\n",
    "df_department = pd.read_csv('department-v2.csv')\n",
    "\n",
    "print(f\"   Seniority: {len(df_seniority)} Eintr√§ge\")\n",
    "print(f\"   Department: {len(df_department)} Eintr√§ge\")\n",
    "\n",
    "# Train-Test Split \n",
    "train_sen, test_sen = train_test_split(\n",
    "    df_seniority,\n",
    "    test_size=0.2,\n",
    "    stratify=df_seniority['label'],\n",
    "    #random_state=config.random_state\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "train_dept, test_dept = train_test_split(\n",
    "    df_department,\n",
    "    test_size=0.2,\n",
    "    stratify=df_department['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n Train-Test Split:\")\n",
    "print(f\"   Seniority - Train: {len(train_sen)}, Test: {len(test_sen)}\")\n",
    "print(f\"   Department - Train: {len(train_dept)}, Test: {len(test_dept)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc98fbb",
   "metadata": {},
   "source": [
    "## 3 TEXT NORMALIZATION & TF-IDF TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f34204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF TRAINING\n",
      "\n",
      "   Classes: ['Director', 'Junior', 'Lead', 'Management', 'Senior']\n",
      "   Classes: ['Administrative', 'Business Development', 'Consulting', 'Customer Support', 'Human Resources', 'Information Technology', 'Marketing', 'Other', 'Project Management', 'Purchasing', 'Sales']\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF TRAINING\\n\")\n",
    "\n",
    "# Text Normalization Function\n",
    "def normalize(text):\n",
    "    \"\"\"Text-Normalization: Umlauts, Gendering, special characters\"\"\"\n",
    "    if text is None or (isinstance(text, float) and pd.isna(text)):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = text.replace(\"√§\",\"ae\").replace(\"√∂\",\"oe\").replace(\"√º\",\"ue\").replace(\"√ü\",\"ss\")\n",
    "    text = re.sub(r\"(innen|in)\\b\", \"\", text)  # Gendering\n",
    "    text = re.sub(r\"[^a-z0-9 ]\", \" \", text)  # Nur Buchstaben/Zahlen\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# TF-IDF Training Function\n",
    "def train_tfidf_model(df, use_char_ngrams=True):\n",
    "    \"\"\"trains TF-IDF + Logistic Regression Model\"\"\"\n",
    "    if use_char_ngrams:\n",
    "        vec = TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5), lowercase=True)\n",
    "    else:\n",
    "        vec = TfidfVectorizer(ngram_range=(1,2), lowercase=True)\n",
    "    \n",
    "    clf = LogisticRegression(max_iter=3000, class_weight=\"balanced\")\n",
    "    pipe = Pipeline([(\"tfidf\", vec), (\"clf\", clf)])\n",
    "    \n",
    "    X = df[\"text\"].astype(str).map(normalize)\n",
    "    y = df[\"label\"].astype(str)\n",
    "    pipe.fit(X, y)\n",
    "    return pipe\n",
    "\n",
    "\n",
    "sen_TFIDF = train_tfidf_model(train_sen, use_char_ngrams=True)\n",
    "print(f\"   Classes: {list(sen_TFIDF.classes_)}\")\n",
    "\n",
    "dept_TFIDF = train_tfidf_model(train_dept, use_char_ngrams=True)\n",
    "print(f\"   Classes: {list(dept_TFIDF.classes_)}\")\n",
    "\n",
    "# Helper Function for Predictions with Confidence\n",
    "def predict_with_confidence(model, text):\n",
    "    \"\"\"TF-IDF Prediction mit Confidence Score\"\"\"\n",
    "    text_norm = normalize(text)\n",
    "    proba = model.predict_proba([text_norm])[0]\n",
    "    pred_idx = int(np.argmax(proba))\n",
    "    pred_label = str(model.classes_[pred_idx])\n",
    "    confidence = float(proba[pred_idx])\n",
    "    return pred_label, confidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fdb5ab",
   "metadata": {},
   "source": [
    "## 4 RULE-BASED SYSTEM SETUP\n",
    "Implements the a Rule-based labeling system. That derives seniority and department from job titles. This involves combining exact text matches, statistically learned keywords from training data, abbreviations and simple heuristics, and merging them into a label by majority decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "860e75cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RULE-BASED SYSTEM SETUP\n",
      "\n",
      "\n",
      "Extrahiere Keywords aus Training Data...\n",
      "Keywords extrahiert:\n",
      "   Seniority: 5 Labels\n",
      "   Department: 11 Labels\n",
      "\n",
      "Erstelle Lookup-Dictionaries...\n",
      "Lookups erstellt:\n",
      "   Seniority: 7162 Eintr√§ge\n",
      "   Department: 7648 Eintr√§ge\n",
      "\n",
      "Rule Labeler erstellt\n"
     ]
    }
   ],
   "source": [
    "print(\"RULE-BASED SYSTEM SETUP\\n\")\n",
    "\n",
    "# Configuration\n",
    "STOPWORDS = set([\"and\",\"of\",\"for\",\"und\",\"der\",\"die\",\"das\",\"in\",\"mit\",\"to\",\"de\",\"la\",\"le\",\"des\",\"et\",\"en\",\"as\"])\n",
    "\n",
    "SENIORITY_ABBR = {\n",
    "    \"jr\": \"Junior\", \"sr\": \"Senior\", \"lead\": \"Lead\", \"chief\": \"Lead\",\n",
    "    \"dir\": \"Director\", \"vp\": \"Director\", \"mgr\": \"Management\"\n",
    "}\n",
    "\n",
    "DEPARTMENT_ABBR = {\n",
    "    \"it\": \"Information Technology\", \"hr\": \"Human Resources\",\n",
    "    \"bd\": \"Business Development\", \"ops\": \"Operations\"\n",
    "}\n",
    "\n",
    "C_LEVEL_ABBR = {\n",
    "    \"CEO\": \"Chief Executive Officer\", \"CFO\": \"Chief Financial Officer\",\n",
    "    \"COO\": \"Chief Operating Officer\", \"CTO\": \"Chief Technology Officer\",\n",
    "    \"CMO\": \"Chief Marketing Officer\", \"CIO\": \"Chief Information Officer\",\n",
    "    \"CHRO\": \"Chief Human Resources Officer\", \"EVP\": \"Executive Vice President\",\n",
    "    \"SVP\": \"Senior Vice President\", \"VP\": \"Vice President\",\n",
    "    \"AVP\": \"Assistant Vice President\",\n",
    "}\n",
    "\n",
    "# Helper Functions\n",
    "def build_keyword_dict(df):\n",
    "    \"\"\"Extrahiert Top-Keywords pro Label aus Training Data\"\"\"\n",
    "    label_words = defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        lab = str(row[\"label\"])\n",
    "        txt = normalize(row[\"text\"])\n",
    "        for w in txt.split():\n",
    "            if len(w) >= 3 and w not in STOPWORDS:\n",
    "                label_words[lab].append(w)\n",
    "    return {lab: dict(Counter(words).most_common(30)) for lab, words in label_words.items()}\n",
    "\n",
    "def vote(labels):\n",
    "    \"\"\"Majority Voting\"\"\"\n",
    "    labels = [l for l in labels if l is not None]\n",
    "    return Counter(labels).most_common(1)[0][0] if labels else None\n",
    "\n",
    "def length_based_seniority(pos_norm):\n",
    "    \"\"\"L√§ngen-basierte Heuristik f√ºr Seniority\"\"\"\n",
    "    n = len(pos_norm.split())\n",
    "    if n <= 3: return \"Junior\"\n",
    "    if n >= 6: return \"Senior\"\n",
    "    return None\n",
    "\n",
    "# Build Keyword Dictionaries\n",
    "print(\"\\nExtrahiere Keywords aus Training Data...\")\n",
    "sen_keywords = build_keyword_dict(train_sen)\n",
    "dept_keywords = build_keyword_dict(train_dept)\n",
    "print(f\"Keywords extrahiert:\")\n",
    "print(f\"   Seniority: {len(sen_keywords)} Labels\")\n",
    "print(f\"   Department: {len(dept_keywords)} Labels\")\n",
    "\n",
    "# Build Lookup Dictionaries\n",
    "print(\"\\nErstelle Lookup-Dictionaries...\")\n",
    "train_sen_norm = train_sen.copy()\n",
    "train_sen_norm[\"text_clean\"] = train_sen_norm[\"text\"].map(normalize)\n",
    "sen_lookup = dict(zip(train_sen_norm[\"text_clean\"], train_sen_norm[\"label\"]))\n",
    "\n",
    "train_dept_norm = train_dept.copy()\n",
    "train_dept_norm[\"text_clean\"] = train_dept_norm[\"text\"].map(normalize)\n",
    "dept_lookup = dict(zip(train_dept_norm[\"text_clean\"], train_dept_norm[\"label\"]))\n",
    "\n",
    "print(f\"Lookups erstellt:\")\n",
    "print(f\"   Seniority: {len(sen_lookup)} Eintr√§ge\")\n",
    "print(f\"   Department: {len(dept_lookup)} Eintr√§ge\")\n",
    "\n",
    "# Rule Labeler Class\n",
    "class RuleLabeler:\n",
    "    \"\"\"Rule-based Labeling System\"\"\"\n",
    "    \n",
    "    def __init__(self, sen_lookup, dept_lookup, sen_keywords, dept_keywords):\n",
    "        self.sen_lookup = sen_lookup\n",
    "        self.dept_lookup = dept_lookup\n",
    "        self.sen_keywords = sen_keywords\n",
    "        self.dept_keywords = dept_keywords\n",
    "    \n",
    "    def label_position(self, position):\n",
    "        \"\"\"Rule-based Labeling f√ºr einen Job Title\"\"\"\n",
    "        pos = normalize(position)\n",
    "        sen_votes = []\n",
    "        dept_votes = []\n",
    "        \n",
    "        # 1. Exact Lookup\n",
    "        sen_votes.append(self.sen_lookup.get(pos))\n",
    "        dept_votes.append(self.dept_lookup.get(pos))\n",
    "        \n",
    "        # 2. Keyword Matching\n",
    "        for lab, kws in self.sen_keywords.items():\n",
    "            for kw in kws.keys():\n",
    "                if kw in pos:\n",
    "                    sen_votes.append(lab)\n",
    "        \n",
    "        for lab, kws in self.dept_keywords.items():\n",
    "            for kw in kws.keys():\n",
    "                if kw in pos:\n",
    "                    dept_votes.append(lab)\n",
    "        \n",
    "        # 3. Abk√ºrzungen\n",
    "        for abbr, lab in SENIORITY_ABBR.items():\n",
    "            if abbr in pos:\n",
    "                sen_votes.append(lab)\n",
    "        \n",
    "        for abbr, lab in DEPARTMENT_ABBR.items():\n",
    "            if abbr in pos:\n",
    "                dept_votes.append(lab)\n",
    "        \n",
    "        # 4. C-Level Detection\n",
    "        for abbr, long in C_LEVEL_ABBR.items():\n",
    "            if abbr.lower() in pos or long.lower() in pos:\n",
    "                sen_votes.append(\"Management\")\n",
    "        \n",
    "        # 5. Length-based Fallback\n",
    "        if all(v is None for v in sen_votes):\n",
    "            len_vote = length_based_seniority(pos)\n",
    "            sen_votes.append(len_vote)\n",
    "        \n",
    "        # 6. Voting\n",
    "        final_sen = vote(sen_votes)\n",
    "        final_dept = vote(dept_votes) or \"Other\"\n",
    "        \n",
    "        return final_sen, final_dept\n",
    "\n",
    "# Create Rule Labeler Instance\n",
    "rule_labeler = RuleLabeler(sen_lookup, dept_lookup, sen_keywords, dept_keywords)\n",
    "print(\"\\nRule Labeler erstellt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4621ca",
   "metadata": {},
   "source": [
    "## 5 LOAD FINE-TUNING MODELS\n",
    "Load the already trained and saved Fine-Tuning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e40e4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINE-TUNING MODELS LOADING\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from 'best_sen_model' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
      "The tokenizer you are loading from 'best_dept_model' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Modelle geladen\n",
      "   Seniority Classes: [np.str_('Junior'), np.str_('Senior'), np.str_('Lead'), np.str_('Management'), np.str_('Director')]\n",
      "   Department Classes: ['Administrative', 'Business Development', 'Consulting', 'Customer Support', 'Human Resources', 'Information Technology', 'Marketing', 'Other', 'Project Management', 'Purchasing', 'Sales']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sophia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.6.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"FINE-TUNING MODELS LOADING\\n\")\n",
    "\n",
    "model_sen_ft = AutoModelForSequenceClassification.from_pretrained('best_sen_model')\n",
    "tokenizer_sen = AutoTokenizer.from_pretrained('best_sen_model')\n",
    "\n",
    "model_dept_ft = AutoModelForSequenceClassification.from_pretrained('best_dept_model')\n",
    "tokenizer_dept = AutoTokenizer.from_pretrained('best_dept_model')\n",
    "\n",
    "# Load Label Encoders\n",
    "import pickle\n",
    "with open('./label_encoders.pkl', 'rb') as f:\n",
    "    label_encoders = pickle.load(f)\n",
    "    le_sen = label_encoders['sen']\n",
    "    le_dept = label_encoders['dept']\n",
    "\n",
    "\n",
    "print(f\"Fine-Tuning Modelle geladen\")\n",
    "print(f\"   Seniority Classes: {list(le_sen.classes_)}\")\n",
    "print(f\"   Department Classes: {list(le_dept.classes_)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623f97c0",
   "metadata": {},
   "source": [
    "## 6 BASELINE COMPARISON \n",
    "This section compares the performance of the three \"Baseline\" Models, which are used for Pseudolabeling and Hybrid prediction later, on the CSV Test-Data.\n",
    "Models:\n",
    "- TF-IDF Model\n",
    "- Fine-Tuning Models\n",
    "- Rule based labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0084156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE COMPARISON - CSV TEST-SET\n",
      "\n",
      "\n",
      "          Model Seniority Department\n",
      "TF-IDF + LogReg    0.9735     0.9487\n",
      "     Rule-Based    0.5911     0.6299\n",
      "    Fine-Tuning    0.9995     0.9975\n"
     ]
    }
   ],
   "source": [
    "print(\"BASELINE COMPARISON - CSV TEST-SET\\n\")\n",
    "\n",
    "# Evaluate TF-IDF\n",
    "X_test_sen = test_sen[\"text\"].astype(str).map(normalize)\n",
    "y_test_sen = test_sen[\"label\"].astype(str)\n",
    "pred_sen_TFIDF = sen_TFIDF.predict(X_test_sen)\n",
    "acc_sen_TFIDF = accuracy_score(y_test_sen, pred_sen_TFIDF)\n",
    "\n",
    "X_test_dept = test_dept[\"text\"].astype(str).map(normalize)\n",
    "y_test_dept = test_dept[\"label\"].astype(str)\n",
    "pred_dept_TFIDF = dept_TFIDF.predict(X_test_dept)\n",
    "acc_dept_TFIDF = accuracy_score(y_test_dept, pred_dept_TFIDF)\n",
    "\n",
    "# Evaluate Rules\n",
    "pred_sen_rules = []\n",
    "true_sen_rules = []\n",
    "for _, row in test_sen.iterrows():\n",
    "    pred_sen, _ = rule_labeler.label_position(row[\"text\"])\n",
    "    if pred_sen is not None:\n",
    "        pred_sen_rules.append(pred_sen)\n",
    "        true_sen_rules.append(row[\"label\"])\n",
    "acc_sen_rules = accuracy_score(true_sen_rules, pred_sen_rules)\n",
    "\n",
    "pred_dept_rules = []\n",
    "true_dept_rules = []\n",
    "for _, row in test_dept.iterrows():\n",
    "    _, pred_dept = rule_labeler.label_position(row[\"text\"])\n",
    "    pred_dept_rules.append(pred_dept)\n",
    "    true_dept_rules.append(row[\"label\"])\n",
    "acc_dept_rules = accuracy_score(true_dept_rules, pred_dept_rules)\n",
    "\n",
    "# Evaluate Fine-Tuning\n",
    "predictions_sen_ft = []\n",
    "true_sen_ft = []\n",
    "for idx, row in test_sen.iterrows():\n",
    "    text = str(row['text']).strip()\n",
    "    inputs = tokenizer_sen(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    #inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model_sen_ft(**inputs)\n",
    "    pred_idx = outputs.logits.argmax().item()\n",
    "    pred_label = le_sen.inverse_transform([pred_idx])[0]\n",
    "    predictions_sen_ft.append(pred_label)\n",
    "    true_sen_ft.append(row['label'])\n",
    "acc_sen_ft = accuracy_score(true_sen_ft, predictions_sen_ft)\n",
    "\n",
    "predictions_dept_ft = []\n",
    "true_dept_ft = []\n",
    "for idx, row in test_dept.iterrows():\n",
    "    text = str(row['text']).strip()\n",
    "    inputs = tokenizer_dept(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    #inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model_dept_ft(**inputs)\n",
    "    pred_idx = outputs.logits.argmax().item()\n",
    "    pred_label = le_dept.inverse_transform([pred_idx])[0]\n",
    "    predictions_dept_ft.append(pred_label)\n",
    "    true_dept_ft.append(row['label'])\n",
    "acc_dept_ft = accuracy_score(true_dept_ft, predictions_dept_ft)\n",
    "\n",
    "# Summary Table\n",
    "baseline_comparison = pd.DataFrame({\n",
    "    'Model': ['TF-IDF + LogReg', 'Rule-Based', 'Fine-Tuning'],\n",
    "    'Seniority': [f'{acc_sen_TFIDF:.4f}', f'{acc_sen_rules:.4f}', f'{acc_sen_ft:.4f}'],\n",
    "    'Department': [f'{acc_dept_TFIDF:.4f}', f'{acc_dept_rules:.4f}', f'{acc_dept_ft:.4f}']\n",
    "})\n",
    "\n",
    "print(\"\\n\" + baseline_comparison.to_string(index=False))\n",
    "#print(\"\\nüí° Diese Modelle werden im 3-Way Ensemble kombiniert f√ºr Pseudo-Labeling\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb0128",
   "metadata": {},
   "source": [
    "## 7 ENSEMBLE PSEUDO-LABELING (3-WAY)\n",
    "\n",
    "This section creates pseudo labels for the not-annotated JASON data with additional CVs. This file will be used later to extract features.\n",
    "\n",
    "The Pseudo-Labels are created with the following rules:\n",
    "\n",
    "1. Predictions of Fine-tuning and TF-IDF agree -> accept Label (confidence = max(FT-Conf, TF-IDF-Conf))\n",
    "2. Predictions of Fine-tuning and Rule-Label agree and FT-Conf >= 75% -> accept Label (confidence = FT-Conf)\n",
    "3. Predictions of TF-IDF and Rule-Label agree and TF-IDF-Conf >= 75% -> accept Label (confidence = TF-IDF-Conf)\n",
    "4. FT-Conf >= 90% -> accept Label (conficence = FT-Conf)\n",
    "5. TF-IDF-Conf >= 90% -> accept Label (conficence = FT-Conf)\n",
    "\n",
    "=> only person where >= 80% of the Jobs have Labels with Conf >= 60% were kept for the Pseudo-Label File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c1b46af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENSEMBLE PSEUDO-LABELING - FT + TF-IDF + RULES\n",
      "\n",
      "\n",
      "Konfiguration:\n",
      "  FT High Confidence:       0.9\n",
      "  TF-IDF High Confidence:   0.9\n",
      "  ML Agreement Threshold:   0.6\n",
      "  Rule Agreement Threshold: 0.75\n",
      "\n",
      "Not-Annotated Data\n",
      " 390 persons geladen\n",
      "Progress: 0/390\n",
      "Progress: 100/390\n",
      "Progress: 200/390\n",
      "Progress: 300/390\n"
     ]
    }
   ],
   "source": [
    "print(\"ENSEMBLE PSEUDO-LABELING - FT + TF-IDF + RULES\\n\")\n",
    "\n",
    "# Configuration\n",
    "@dataclass\n",
    "class EnsemblePseudoConfig:\n",
    "    ft_hi: float = 0.90           # Fine-Tuning sehr sicher\n",
    "    tfidf_hi: float = 0.90        # TF-IDF sehr sicher\n",
    "    ml_agree_min: float = 0.60    # Beide ML √ºbereinstimmen\n",
    "    rule_agree_min: float = 0.75  # ML + Rules √ºbereinstimmen\n",
    "    min_keep_ratio: float = 0.80  # Person Filter\n",
    "    min_conf_for_person: float = 0.60\n",
    "    only_active: bool = True\n",
    "\n",
    "ensemble_cfg = EnsemblePseudoConfig()\n",
    "\n",
    "print(\"\\nKonfiguration:\")\n",
    "print(f\"  FT High Confidence:       {ensemble_cfg.ft_hi}\")\n",
    "print(f\"  TF-IDF High Confidence:   {ensemble_cfg.tfidf_hi}\")\n",
    "print(f\"  ML Agreement Threshold:   {ensemble_cfg.ml_agree_min}\")\n",
    "print(f\"  Rule Agreement Threshold: {ensemble_cfg.rule_agree_min}\")\n",
    "\n",
    "# Ensemble Pseudo-Labeling Function\n",
    "def ensemble_pseudo_label_job(\n",
    "    job: Dict[str, Any],\n",
    "    ft_model_sen, ft_model_dept,\n",
    "    ft_tokenizer_sen, ft_tokenizer_dept,\n",
    "    ft_le_sen, ft_le_dept,\n",
    "    tfidf_model_sen, tfidf_model_dept,\n",
    "    rule_labeler,\n",
    "    cfg: EnsemblePseudoConfig\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"3-Way Ensemble: Fine-Tuning + TF-IDF + Rules\"\"\"\n",
    "    \n",
    "    out = dict(job)\n",
    "    pos = str(job.get(\"position\", \"\")).strip()\n",
    "    \n",
    "    # SENIORITY\n",
    "    # 1. Fine-Tuning\n",
    "    inputs_sen = ft_tokenizer_sen(pos, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs_sen = ft_model_sen(**inputs_sen)\n",
    "    ft_probs_sen = torch.nn.functional.softmax(outputs_sen.logits, dim=-1)\n",
    "    ft_conf_sen = ft_probs_sen.max().item()\n",
    "    ft_pred_idx_sen = outputs_sen.logits.argmax().item()\n",
    "    ft_pred_sen = ft_le_sen.inverse_transform([ft_pred_idx_sen])[0]\n",
    "    \n",
    "    # 2. TF-IDF\n",
    "    tfidf_pred_sen, tfidf_conf_sen = predict_with_confidence(tfidf_model_sen, pos)\n",
    "    \n",
    "    # 3. Rules\n",
    "    rule_pred_sen, _ = rule_labeler.label_position(pos)\n",
    "    \n",
    "    # 4. Ensemble Logic\n",
    "    if ft_pred_sen == tfidf_pred_sen:\n",
    "        sen_label = ft_pred_sen\n",
    "        sen_source = \"ml_agree\"\n",
    "        sen_conf = max(ft_conf_sen, tfidf_conf_sen)\n",
    "    elif rule_pred_sen and ft_pred_sen == rule_pred_sen and ft_conf_sen >= cfg.rule_agree_min:\n",
    "        sen_label = ft_pred_sen\n",
    "        sen_source = \"ft_rule_agree\"\n",
    "        sen_conf = ft_conf_sen\n",
    "    elif rule_pred_sen and tfidf_pred_sen == rule_pred_sen and tfidf_conf_sen >= cfg.rule_agree_min:\n",
    "        sen_label = tfidf_pred_sen\n",
    "        sen_source = \"tfidf_rule_agree\"\n",
    "        sen_conf = tfidf_conf_sen\n",
    "    elif ft_conf_sen >= cfg.ft_hi:\n",
    "        sen_label = ft_pred_sen\n",
    "        sen_source = \"ft_hi\"\n",
    "        sen_conf = ft_conf_sen\n",
    "    elif tfidf_conf_sen >= cfg.tfidf_hi:\n",
    "        sen_label = tfidf_pred_sen\n",
    "        sen_source = \"tfidf_hi\"\n",
    "        sen_conf = tfidf_conf_sen\n",
    "    else:\n",
    "        sen_label = None\n",
    "        sen_source = None\n",
    "        sen_conf = max(ft_conf_sen, tfidf_conf_sen)\n",
    "    \n",
    "    # DEPARTMENT (gleiche Logik)\n",
    "    inputs_dept = ft_tokenizer_dept(pos, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs_dept = ft_model_dept(**inputs_dept)\n",
    "    ft_probs_dept = torch.nn.functional.softmax(outputs_dept.logits, dim=-1)\n",
    "    ft_conf_dept = ft_probs_dept.max().item()\n",
    "    ft_pred_idx_dept = outputs_dept.logits.argmax().item()\n",
    "    ft_pred_dept = ft_le_dept.inverse_transform([ft_pred_idx_dept])[0]\n",
    "    \n",
    "    tfidf_pred_dept, tfidf_conf_dept = predict_with_confidence(tfidf_model_dept, pos)\n",
    "    _, rule_pred_dept = rule_labeler.label_position(pos)\n",
    "    \n",
    "    if ft_pred_dept == tfidf_pred_dept:\n",
    "        dept_label = ft_pred_dept\n",
    "        dept_source = \"ml_agree\"\n",
    "        dept_conf = max(ft_conf_dept, tfidf_conf_dept)\n",
    "    elif rule_pred_dept and ft_pred_dept == rule_pred_dept and ft_conf_dept >= cfg.rule_agree_min:\n",
    "        dept_label = ft_pred_dept\n",
    "        dept_source = \"ft_rule_agree\"\n",
    "        dept_conf = ft_conf_dept\n",
    "    elif rule_pred_dept and tfidf_pred_dept == rule_pred_dept and tfidf_conf_dept >= cfg.rule_agree_min:\n",
    "        dept_label = tfidf_pred_dept\n",
    "        dept_source = \"tfidf_rule_agree\"\n",
    "        dept_conf = tfidf_conf_dept\n",
    "    elif ft_conf_dept >= cfg.ft_hi:\n",
    "        dept_label = ft_pred_dept\n",
    "        dept_source = \"ft_hi\"\n",
    "        dept_conf = ft_conf_dept\n",
    "    elif tfidf_conf_dept >= cfg.tfidf_hi:\n",
    "        dept_label = tfidf_pred_dept\n",
    "        dept_source = \"tfidf_hi\"\n",
    "        dept_conf = tfidf_conf_dept\n",
    "    else:\n",
    "        dept_label = None\n",
    "        dept_source = None\n",
    "        dept_conf = max(ft_conf_dept, tfidf_conf_dept)\n",
    "    \n",
    "    # Output\n",
    "    out['seniority'] = sen_label\n",
    "    out['department'] = dept_label\n",
    "    out['confidence_sen'] = float(sen_conf)\n",
    "    out['confidence_dept'] = float(dept_conf)\n",
    "    out['pseudo_source_sen'] = sen_source\n",
    "    out['pseudo_source_dept'] = dept_source\n",
    "    \n",
    "    return out\n",
    "\n",
    "# Apply to Dataset\n",
    "def ensemble_pseudo_label_dataset(data, cfg):\n",
    "    \"\"\"Apply ensemble pseudo-labeling to entire dataset\"\"\"\n",
    "    labeled = []\n",
    "    for person_idx, person_jobs in enumerate(data):\n",
    "        if person_idx % 100 == 0:\n",
    "            print(f\"Progress: {person_idx}/{len(data)}\")\n",
    "        \n",
    "        labeled_jobs = []\n",
    "        for job in person_jobs:\n",
    "            if cfg.only_active and job.get(\"status\") != \"ACTIVE\":\n",
    "                labeled_jobs.append(dict(job))\n",
    "            else:\n",
    "                labeled_job = ensemble_pseudo_label_job(\n",
    "                    job,\n",
    "                    model_sen_ft, model_dept_ft,\n",
    "                    tokenizer_sen, tokenizer_dept,\n",
    "                    le_sen, le_dept,\n",
    "                    sen_TFIDF, dept_TFIDF,\n",
    "                    rule_labeler,\n",
    "                    cfg\n",
    "                )\n",
    "                labeled_jobs.append(labeled_job)\n",
    "        labeled.append(labeled_jobs)\n",
    "    return labeled\n",
    "\n",
    "# Load Not-Annotated Data\n",
    "print(\"\\nNot-Annotated Data\")\n",
    "with open('linkedin-cvs-not-annotated.json', 'r', encoding='utf-8') as f:\n",
    "    not_annotated = json.load(f)\n",
    "print(f\" {len(not_annotated)} persons geladen\")\n",
    "\n",
    "\n",
    "pseudo_all = ensemble_pseudo_label_dataset(not_annotated, ensemble_cfg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd8d51",
   "metadata": {},
   "source": [
    "## 8 STATISTICS & PERSON-LEVEL FILTERING\n",
    "\n",
    "Provides an overview of the resulting pseudo-label file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "290354d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATISTICS & PERSON-LEVEL FILTERING\n",
      "\n",
      "\n",
      "STATISTICS - BEFORE FILTERING\n",
      "  Total jobs: 1886\n",
      "  Active jobs: 419\n",
      "\n",
      "  Seniority Label Sources:\n",
      "pseudo_source_sen\n",
      "ml_agree            306\n",
      "ft_rule_agree        45\n",
      "ft_hi                37\n",
      "tfidf_rule_agree      4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  Department Label Sources:\n",
      "pseudo_source_dept\n",
      "ml_agree            238\n",
      "ft_hi                39\n",
      "ft_rule_agree        21\n",
      "tfidf_rule_agree      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  Label Coverage:\n",
      "    Seniority:  20.8%\n",
      "    Department: 15.9%\n",
      "\n",
      "PERSON-LEVEL FILTERING\n",
      "  Minimum Confidence: 0.6\n",
      "  Minimum Keep Ratio: 0.8\n",
      "\n",
      "  Persons kept: 183/390 (46.9%)\n",
      "\n",
      "STATISTICS - AFTER FILTERING\n",
      "  Total jobs: 1001\n",
      "  Active jobs: 213\n",
      "\n",
      "  Seniority Labels:\n",
      "seniority\n",
      "Senior        82\n",
      "Management    63\n",
      "Lead          31\n",
      "Junior        22\n",
      "Director      15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  Department Labels:\n",
      "department\n",
      "Information Technology    88\n",
      "Administrative            27\n",
      "Consulting                23\n",
      "Project Management        18\n",
      "Sales                     17\n",
      "Marketing                 11\n",
      "Purchasing                 9\n",
      "Business Development       8\n",
      "Human Resources            8\n",
      "Other                      2\n",
      "Customer Support           2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"STATISTICS & PERSON-LEVEL FILTERING\\n\")\n",
    "\n",
    "# Statistics Before Filtering\n",
    "all_jobs = []\n",
    "for person in pseudo_all:\n",
    "    all_jobs.extend(person)\n",
    "df_all = pd.DataFrame(all_jobs)\n",
    "\n",
    "print(\"\\nSTATISTICS - BEFORE FILTERING\")\n",
    "print(f\"  Total jobs: {len(df_all)}\")\n",
    "print(f\"  Active jobs: {(df_all['status'] == 'ACTIVE').sum()}\")\n",
    "\n",
    "print(\"\\n  Seniority Label Sources:\")\n",
    "print(df_all['pseudo_source_sen'].value_counts())\n",
    "\n",
    "print(\"\\n  Department Label Sources:\")\n",
    "print(df_all['pseudo_source_dept'].value_counts())\n",
    "\n",
    "sen_coverage = (df_all['seniority'].notna()).sum() / len(df_all) * 100\n",
    "dept_coverage = (df_all['department'].notna()).sum() / len(df_all) * 100\n",
    "print(f\"\\n  Label Coverage:\")\n",
    "print(f\"    Seniority:  {sen_coverage:.1f}%\")\n",
    "print(f\"    Department: {dept_coverage:.1f}%\")\n",
    "\n",
    "# Person-Level Filtering\n",
    "def filter_persons_by_confidence(labeled_data, min_confidence, min_keep_ratio, only_active=True):\n",
    "    \"\"\"Filter persons where too many jobs have uncertain labels\"\"\"\n",
    "    filtered = []\n",
    "    for person_jobs in labeled_data:\n",
    "        considered = [j for j in person_jobs if (not only_active) or j.get(\"status\") == \"ACTIVE\"]\n",
    "        total = len(considered)\n",
    "        if total == 0:\n",
    "            continue\n",
    "        \n",
    "        confident = 0\n",
    "        for job in considered:\n",
    "            cs = float(job.get('confidence_sen', 0))\n",
    "            cd = float(job.get('confidence_dept', 0))\n",
    "            if (cs >= min_confidence and cd >= min_confidence \n",
    "                and job.get('seniority') and job.get('department')):\n",
    "                confident += 1\n",
    "        \n",
    "        keep_ratio = confident / total if total > 0 else 0\n",
    "        if keep_ratio >= min_keep_ratio:\n",
    "            filtered.append(person_jobs)\n",
    "    return filtered\n",
    "\n",
    "print(\"\\nPERSON-LEVEL FILTERING\")\n",
    "print(f\"  Minimum Confidence: {ensemble_cfg.min_conf_for_person}\")\n",
    "print(f\"  Minimum Keep Ratio: {ensemble_cfg.min_keep_ratio}\")\n",
    "\n",
    "pseudo_filtered = filter_persons_by_confidence(\n",
    "    pseudo_all,\n",
    "    min_confidence=ensemble_cfg.min_conf_for_person,\n",
    "    min_keep_ratio=ensemble_cfg.min_keep_ratio,\n",
    "    only_active=ensemble_cfg.only_active\n",
    ")\n",
    "\n",
    "print(f\"\\n  Persons kept: {len(pseudo_filtered)}/{len(pseudo_all)} ({len(pseudo_filtered)/len(pseudo_all)*100:.1f}%)\")\n",
    "\n",
    "# Statistics After Filtering\n",
    "filtered_jobs = []\n",
    "for person in pseudo_filtered:\n",
    "    filtered_jobs.extend(person)\n",
    "df_filtered = pd.DataFrame(filtered_jobs)\n",
    "\n",
    "print(\"\\nSTATISTICS - AFTER FILTERING\")\n",
    "print(f\"  Total jobs: {len(df_filtered)}\")\n",
    "print(f\"  Active jobs: {(df_filtered['status'] == 'ACTIVE').sum()}\")\n",
    "\n",
    "print(\"\\n  Seniority Labels:\")\n",
    "print(df_filtered['seniority'].value_counts())\n",
    "\n",
    "print(\"\\n  Department Labels:\")\n",
    "print(df_filtered['department'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7de56c",
   "metadata": {},
   "source": [
    "## 9 SAVE PSEUDO-LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57bd5422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVE PSEUDO-LABELS\n",
      "\n",
      "\n",
      "Pseudo-Labels saved: linkedin_pseudo_labeled_ensemble.json\n",
      "   183 persons\n",
      "   1001 total jobs\n"
     ]
    }
   ],
   "source": [
    "print(\"SAVE PSEUDO-LABELS\\n\")\n",
    "\n",
    "output_filename = 'linkedin_pseudo_labeled_ensemble.json'\n",
    "\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(pseudo_filtered, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nPseudo-Labels saved: {output_filename}\")\n",
    "print(f\"   {len(pseudo_filtered)} persons\")\n",
    "print(f\"   {len(df_filtered)} total jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237fb16d",
   "metadata": {},
   "source": [
    "## 10 FEATURE ENGINEERING & RANDOM FOREST TRAINING\n",
    "- Person-based grouped split of the Pseudo-Labeled File in Test and Train Data\n",
    "- Feature extraction and random forest training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90697e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE ENGINEERING & RANDOM FOREST\n",
      "\n",
      "\n",
      "Feature Set: 24 Features\n",
      "   Seniority: 213 Jobs von 183 Personen\n",
      "   Department: 213 Jobs von 183 Personen\n",
      "SENIORITY MODEL\n",
      "\n",
      "\n",
      "Person-based Train-Test-Split:\n",
      "   Train: 165 Jobs von 146 Personen\n",
      "   Test:  48 Jobs von 37 Personen\n",
      "\n",
      "   Train Labels: [np.str_('Director'), np.str_('Junior'), np.str_('Lead'), np.str_('Management'), np.str_('Senior')]\n",
      "   Test Labels:  [np.str_('Director'), np.str_('Junior'), np.str_('Lead'), np.str_('Management'), np.str_('Senior')]\n",
      "\n",
      "SENIORITY TEST ACCURACY:       0.3958 (39.58%)\n",
      "\n",
      "Classification Report (Seniority):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Director       0.00      0.00      0.00         2\n",
      "      Junior       0.50      0.12      0.20         8\n",
      "        Lead       1.00      0.08      0.15        12\n",
      "  Management       0.43      0.75      0.55        12\n",
      "      Senior       0.36      0.57      0.44        14\n",
      "\n",
      "    accuracy                           0.40        48\n",
      "   macro avg       0.46      0.31      0.27        48\n",
      "weighted avg       0.55      0.40      0.34        48\n",
      "\n",
      "DEPARTMENT MODEL\n",
      "\n",
      "\n",
      "Person-based Train-Test-Split:\n",
      "   Train: 165 Jobs von 146 Personen\n",
      "   Test:  48 Jobs von 37 Personen\n",
      "\n",
      "   Train Labels: ['Administrative', 'Business Development', 'Consulting', 'Customer Support', 'Human Resources', 'Information Technology', 'Marketing', 'Other', 'Project Management', 'Purchasing', 'Sales']\n",
      "   Test Labels:  ['Administrative', 'Business Development', 'Consulting', 'Human Resources', 'Information Technology', 'Marketing', 'Project Management', 'Purchasing', 'Sales']\n",
      "\n",
      "DEPARTMENT TEST ACCURACY:      0.2917 (29.17%)\n",
      "\n",
      "Classification Report (Department):\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        Administrative       0.11      0.20      0.14         5\n",
      "  Business Development       0.00      0.00      0.00         1\n",
      "            Consulting       1.00      0.11      0.20         9\n",
      "       Human Resources       0.00      0.00      0.00         3\n",
      "Information Technology       0.41      0.60      0.49        20\n",
      "             Marketing       0.00      0.00      0.00         1\n",
      "    Project Management       0.00      0.00      0.00         4\n",
      "            Purchasing       0.00      0.00      0.00         1\n",
      "                 Sales       0.00      0.00      0.00         4\n",
      "\n",
      "              accuracy                           0.29        48\n",
      "             macro avg       0.17      0.10      0.09        48\n",
      "          weighted avg       0.37      0.29      0.26        48\n",
      "\n",
      "\n",
      "Summary\n",
      "\n",
      "Seniority Test Accuracy:   39.58%\n",
      "Department Test Accuracy:  29.17%\n"
     ]
    }
   ],
   "source": [
    "print(\"FEATURE ENGINEERING & RANDOM FOREST\\n\")\n",
    "\n",
    "# Feature Extraction Functions\n",
    "def calculate_months_between(start_date, end_date):\n",
    "    \"\"\"Berechnet Monate zwischen zwei Daten\"\"\"\n",
    "    try:\n",
    "        start = pd.to_datetime(start_date)\n",
    "        end = pd.to_datetime(end_date) if end_date else pd.to_datetime(datetime.now())\n",
    "        return float((end - start).days / 30)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def extract_job_history_features(person_jobs, target_job_idx=0):\n",
    "    \"\"\"Extrahiert 24 Features aus Job-Historie\"\"\"\n",
    "    target_job = person_jobs[target_job_idx]\n",
    "    \n",
    "    features = {\n",
    "        'total_jobs': len(person_jobs),\n",
    "        'job_number': target_job_idx + 1,\n",
    "        'previous_seniority_junior': 0,\n",
    "        'previous_seniority_professional': 0,\n",
    "        'previous_seniority_senior': 0,\n",
    "        'previous_seniority_lead': 0,\n",
    "        'previous_seniority_management': 0,\n",
    "        'previous_seniority_director': 0,\n",
    "        'previous_dept_administrative': 0,\n",
    "        'previous_dept_business_dev': 0,\n",
    "        'previous_dept_consulting': 0,\n",
    "        'previous_dept_customer_support': 0,\n",
    "        'previous_dept_hr': 0,\n",
    "        'previous_dept_it': 0,\n",
    "        'previous_dept_marketing': 0,\n",
    "        'previous_dept_other': 0,\n",
    "        'previous_dept_project_mgmt': 0,\n",
    "        'previous_dept_purchasing': 0,\n",
    "        'previous_dept_sales': 0,\n",
    "        'same_department_as_previous': 0,\n",
    "        'months_in_current_job': 0.0,\n",
    "        'avg_job_duration': 0.0,\n",
    "        'seniority_increases': 0,\n",
    "        'department_changes': 0,\n",
    "    }\n",
    "    \n",
    "    # Previous Job\n",
    "    if len(person_jobs) > target_job_idx + 1:\n",
    "        prev_job = person_jobs[target_job_idx + 1]\n",
    "        prev_sen = prev_job.get('seniority')\n",
    "        \n",
    "        if prev_sen == 'Junior': features['previous_seniority_junior'] = 1\n",
    "        elif prev_sen == 'Professional': features['previous_seniority_professional'] = 1\n",
    "        elif prev_sen == 'Senior': features['previous_seniority_senior'] = 1\n",
    "        elif prev_sen == 'Lead': features['previous_seniority_lead'] = 1\n",
    "        elif prev_sen == 'Management': features['previous_seniority_management'] = 1\n",
    "        elif prev_sen == 'Director': features['previous_seniority_director'] = 1\n",
    "        \n",
    "        prev_dept = prev_job.get('department')\n",
    "        dept_map = {\n",
    "            'Administrative': 'previous_dept_administrative',\n",
    "            'Business Development': 'previous_dept_business_dev',\n",
    "            'Consulting': 'previous_dept_consulting',\n",
    "            'Customer Support': 'previous_dept_customer_support',\n",
    "            'Human Resources': 'previous_dept_hr',\n",
    "            'Information Technology': 'previous_dept_it',\n",
    "            'Marketing': 'previous_dept_marketing',\n",
    "            'Other': 'previous_dept_other',\n",
    "            'Project Management': 'previous_dept_project_mgmt',\n",
    "            'Purchasing': 'previous_dept_purchasing',\n",
    "            'Sales': 'previous_dept_sales',\n",
    "        }\n",
    "        if prev_dept in dept_map:\n",
    "            features[dept_map[prev_dept]] = 1\n",
    "        \n",
    "        if prev_dept and target_job.get('department') and prev_dept == target_job.get('department'):\n",
    "            features['same_department_as_previous'] = 1\n",
    "    \n",
    "    # Time Features\n",
    "    features['months_in_current_job'] = calculate_months_between(\n",
    "        target_job.get('startDate'), target_job.get('endDate')\n",
    "    )\n",
    "    \n",
    "    durations = []\n",
    "    for job in person_jobs:\n",
    "        dur = calculate_months_between(job.get('startDate'), job.get('endDate'))\n",
    "        if dur > 0:\n",
    "            durations.append(dur)\n",
    "    if durations:\n",
    "        features['avg_job_duration'] = float(np.mean(durations))\n",
    "    \n",
    "    # Progression Features\n",
    "    seniority_order = {'Junior': 1, 'Professional': 2, 'Senior': 3, 'Lead': 4, 'Management': 5, 'Director': 6}\n",
    "    for i in range(len(person_jobs) - 1, 0, -1):\n",
    "        older_sen = person_jobs[i].get('seniority')\n",
    "        newer_sen = person_jobs[i-1].get('seniority')\n",
    "        if older_sen and newer_sen:\n",
    "            if seniority_order.get(newer_sen, 0) > seniority_order.get(older_sen, 0):\n",
    "                features['seniority_increases'] += 1\n",
    "    \n",
    "    for i in range(len(person_jobs) - 1):\n",
    "        if person_jobs[i].get('department') != person_jobs[i+1].get('department'):\n",
    "            features['department_changes'] += 1\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Feature Set Definition\n",
    "FEATURE_COLS = [\n",
    "    'total_jobs', 'job_number',\n",
    "    'previous_seniority_junior', 'previous_seniority_professional',\n",
    "    'previous_seniority_senior', 'previous_seniority_lead',\n",
    "    'previous_seniority_management', 'previous_seniority_director',\n",
    "    'previous_dept_administrative', 'previous_dept_business_dev',\n",
    "    'previous_dept_consulting', 'previous_dept_customer_support',\n",
    "    'previous_dept_hr', 'previous_dept_it', 'previous_dept_marketing',\n",
    "    'previous_dept_other', 'previous_dept_project_mgmt',\n",
    "    'previous_dept_purchasing', 'previous_dept_sales',\n",
    "    'same_department_as_previous',\n",
    "    'months_in_current_job', 'avg_job_duration',\n",
    "    'seniority_increases', 'department_changes'\n",
    "]\n",
    "\n",
    "print(f\"\\nFeature Set: {len(FEATURE_COLS)} Features\")\n",
    "\n",
    "# Build Training DataFrames mit Person-ID\n",
    "def build_feature_dataframes_with_person_id(persons_list):\n",
    "    \"\"\"Extrahiert Features f√ºr alle aktiven Jobs mit Person-ID\"\"\"\n",
    "    rows_sen = []\n",
    "    rows_dept = []\n",
    "    \n",
    "    for person_id, person_jobs in enumerate(persons_list):\n",
    "        for idx, job in enumerate(person_jobs):\n",
    "            if job.get('status') == 'ACTIVE' and job.get('seniority') and job.get('department'):\n",
    "                features = extract_job_history_features(person_jobs, idx)\n",
    "                \n",
    "                row_sen = features.copy()\n",
    "                row_sen['label'] = job['seniority']\n",
    "                row_sen['person_id'] = person_id\n",
    "                rows_sen.append(row_sen)\n",
    "                \n",
    "                row_dept = features.copy()\n",
    "                row_dept['label'] = job['department']\n",
    "                row_dept['person_id'] = person_id\n",
    "                rows_dept.append(row_dept)\n",
    "    \n",
    "    return pd.DataFrame(rows_sen), pd.DataFrame(rows_dept)\n",
    "\n",
    "#extract Features\n",
    "df_rf_sen, df_rf_dept = build_feature_dataframes_with_person_id(pseudo_filtered)\n",
    "\n",
    "print(f\"   Seniority: {len(df_rf_sen)} Jobs von {df_rf_sen['person_id'].nunique()} Personen\")\n",
    "print(f\"   Department: {len(df_rf_dept)} Jobs von {df_rf_dept['person_id'].nunique()} Personen\")\n",
    "\n",
    "# Person-based Split for Seniority\n",
    "print(\"SENIORITY MODEL\\n\")\n",
    "\n",
    "# Person IDs\n",
    "unique_persons_sen = df_rf_sen['person_id'].unique()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(unique_persons_sen)\n",
    "\n",
    "# 80/20 Split\n",
    "split_idx = int(len(unique_persons_sen) * 0.8)\n",
    "train_persons_sen = unique_persons_sen[:split_idx]\n",
    "test_persons_sen = unique_persons_sen[split_idx:]\n",
    "\n",
    "# Train/Test Sets based on Person-IDs\n",
    "df_sen_train = df_rf_sen[df_rf_sen['person_id'].isin(train_persons_sen)]\n",
    "df_sen_test = df_rf_sen[df_rf_sen['person_id'].isin(test_persons_sen)]\n",
    "\n",
    "X_sen_train = df_sen_train[FEATURE_COLS].fillna(0)\n",
    "y_sen_train = df_sen_train['label']\n",
    "X_sen_test = df_sen_test[FEATURE_COLS].fillna(0)\n",
    "y_sen_test = df_sen_test['label']\n",
    "\n",
    "print(f\"\\nPerson-based Train-Test-Split:\")\n",
    "print(f\"   Train: {len(X_sen_train)} Jobs von {len(train_persons_sen)} Personen\")\n",
    "print(f\"   Test:  {len(X_sen_test)} Jobs von {len(test_persons_sen)} Personen\")\n",
    "print(f\"\\n   Train Labels: {sorted(y_sen_train.unique())}\")\n",
    "print(f\"   Test Labels:  {sorted(y_sen_test.unique())}\")\n",
    "\n",
    "# fit LabelEncoder \n",
    "le_sen_rf = LabelEncoder()\n",
    "le_sen_rf.fit(df_rf_sen['label']) \n",
    "y_sen_train_enc = le_sen_rf.transform(y_sen_train)\n",
    "y_sen_test_enc = le_sen_rf.transform(y_sen_test)\n",
    "\n",
    "#train seniority random Forest\n",
    "rf_sen = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf_sen.fit(X_sen_train, y_sen_train_enc)\n",
    "\n",
    "\n",
    "# Predictions and Accuracy\n",
    "y_sen_pred = rf_sen.predict(X_sen_test)\n",
    "sen_accuracy = accuracy_score(y_sen_test_enc, y_sen_pred)\n",
    "\n",
    "print(f\"\\n{'SENIORITY TEST ACCURACY:':<30} {sen_accuracy:.4f} ({sen_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Classification Report \n",
    "print(\"\\nClassification Report (Seniority):\")\n",
    "test_labels = sorted(set(y_sen_test_enc))\n",
    "test_names = [le_sen_rf.classes_[i] for i in test_labels]\n",
    "print(classification_report(y_sen_test_enc, y_sen_pred, \n",
    "                          labels=test_labels,\n",
    "                          target_names=test_names, \n",
    "                          zero_division=0))\n",
    "\n",
    "# Person-based Split for Department\n",
    "print(\"DEPARTMENT MODEL\\n\")\n",
    "\n",
    "# Eindeutige Person IDs\n",
    "unique_persons_dept = df_rf_dept['person_id'].unique()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(unique_persons_dept)\n",
    "\n",
    "# 80/20 Split\n",
    "split_idx = int(len(unique_persons_dept) * 0.8)\n",
    "train_persons_dept = unique_persons_dept[:split_idx]\n",
    "test_persons_dept = unique_persons_dept[split_idx:]\n",
    "\n",
    "# Train/Test Sets based on Person-IDs\n",
    "df_dept_train = df_rf_dept[df_rf_dept['person_id'].isin(train_persons_dept)]\n",
    "df_dept_test = df_rf_dept[df_rf_dept['person_id'].isin(test_persons_dept)]\n",
    "\n",
    "X_dept_train = df_dept_train[FEATURE_COLS].fillna(0)\n",
    "y_dept_train = df_dept_train['label']\n",
    "X_dept_test = df_dept_test[FEATURE_COLS].fillna(0)\n",
    "y_dept_test = df_dept_test['label']\n",
    "\n",
    "print(f\"\\nPerson-based Train-Test-Split:\")\n",
    "print(f\"   Train: {len(X_dept_train)} Jobs von {len(train_persons_dept)} Personen\")\n",
    "print(f\"   Test:  {len(X_dept_test)} Jobs von {len(test_persons_dept)} Personen\")\n",
    "print(f\"\\n   Train Labels: {sorted(y_dept_train.unique())}\")\n",
    "print(f\"   Test Labels:  {sorted(y_dept_test.unique())}\")\n",
    "\n",
    "# fit LabelEncoder\n",
    "le_dept_rf = LabelEncoder()\n",
    "le_dept_rf.fit(df_rf_dept['label'])  \n",
    "y_dept_train_enc = le_dept_rf.transform(y_dept_train)\n",
    "y_dept_test_enc = le_dept_rf.transform(y_dept_test)\n",
    "\n",
    "# train department Random Forest\n",
    "rf_dept = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf_dept.fit(X_dept_train, y_dept_train_enc)\n",
    "\n",
    "# Predictions and Accuracy\n",
    "y_dept_pred = rf_dept.predict(X_dept_test)\n",
    "dept_accuracy = accuracy_score(y_dept_test_enc, y_dept_pred)\n",
    "\n",
    "print(f\"\\n{'DEPARTMENT TEST ACCURACY:':<30} {dept_accuracy:.4f} ({dept_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report (Department):\")\n",
    "test_labels = sorted(set(y_dept_test_enc))\n",
    "test_names = [le_dept_rf.classes_[i] for i in test_labels]\n",
    "print(classification_report(y_dept_test_enc, y_dept_pred,\n",
    "                          labels=test_labels,\n",
    "                          target_names=test_names,\n",
    "                          zero_division=0))\n",
    "\n",
    "# Summary\n",
    "print(\"\\nSummary\\n\")\n",
    "print(f\"Seniority Test Accuracy:   {sen_accuracy*100:.2f}%\")\n",
    "print(f\"Department Test Accuracy:  {dept_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c355ac3",
   "metadata": {},
   "source": [
    "## 11 OPTUNA HYPERPARAMETER TUNING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "401724f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTUNA HYPERPARAMETER TUNING\n",
      "\n",
      "SENIORITY HYPERPARAMETER OPTIMIZATION\n",
      "\n",
      "   Train: 165 Samples\n",
      "   Test:  48 Samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627a8efa7e0e4fc49359290551a8b570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Best Params:\n",
      "      n_estimators: 200\n",
      "      max_depth: 17\n",
      "      min_samples_split: 4\n",
      "      min_samples_leaf: 1\n",
      "      max_features: log2\n",
      "\n",
      "OPTIMIZED SENIORITY TEST ACCURACY:  0.3958 (39.58%)\n",
      "OPTIMIZED SENIORITY TEST F1-MACRO:  0.2336\n",
      "\n",
      "Classification Report (Optimized Seniority):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Director       0.00      0.00      0.00         2\n",
      "      Junior       0.00      0.00      0.00         8\n",
      "        Lead       1.00      0.08      0.15        12\n",
      "  Management       0.39      0.75      0.51        12\n",
      "      Senior       0.41      0.64      0.50        14\n",
      "\n",
      "    accuracy                           0.40        48\n",
      "   macro avg       0.36      0.30      0.23        48\n",
      "weighted avg       0.47      0.40      0.31        48\n",
      "\n",
      "DEPARTMENT HYPERPARAMETER OPTIMIZATION\n",
      "\n",
      "   Train: 165 Samples\n",
      "   Test:  48 Samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea73071f225411a80cd1cb4e6f1cd0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Best Params:\n",
      "      n_estimators: 800\n",
      "      max_depth: 14\n",
      "      min_samples_split: 9\n",
      "      min_samples_leaf: 1\n",
      "      max_features: log2\n",
      "\n",
      "OPTIMIZED DEPARTMENT TEST ACCURACY: 0.3333 (33.33%)\n",
      "OPTIMIZED DEPARTMENT TEST F1-MACRO: 0.0906\n",
      "\n",
      "Classification Report (Optimized Department):\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        Administrative       0.20      0.40      0.27         5\n",
      "  Business Development       0.00      0.00      0.00         1\n",
      "            Consulting       0.00      0.00      0.00         9\n",
      "       Human Resources       0.00      0.00      0.00         3\n",
      "Information Technology       0.45      0.70      0.55        20\n",
      "             Marketing       0.00      0.00      0.00         1\n",
      "    Project Management       0.00      0.00      0.00         4\n",
      "            Purchasing       0.00      0.00      0.00         1\n",
      "                 Sales       0.00      0.00      0.00         4\n",
      "\n",
      "              accuracy                           0.33        48\n",
      "             macro avg       0.07      0.12      0.09        48\n",
      "          weighted avg       0.21      0.33      0.26        48\n",
      "\n",
      "\n",
      "BASELINE vs. OPTIMIZED\n",
      "Modell               Baseline Accuracy    Optimized Accuracy  \n",
      "Seniority                        39.58%               39.58%\n",
      "Department                       29.17%               33.33%\n"
     ]
    }
   ],
   "source": [
    "print(\"OPTUNA HYPERPARAMETER TUNING\\n\")\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def create_rf_objective(X_train, y_train, X_val, y_val):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_categorical('n_estimators', [200, 400, 600, 800]),\n",
    "            'max_depth': trial.suggest_int('max_depth', 8, 20),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 8),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "            'bootstrap': True,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        \n",
    "        rf = RandomForestClassifier(**params)\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        # Prediction on Validation Set\n",
    "        y_pred = rf.predict(X_val)\n",
    "        f1 = f1_score(y_val, y_pred, average='macro', zero_division=0)\n",
    "        \n",
    "        return f1\n",
    "    \n",
    "    return objective\n",
    "\n",
    "# Seniority Tuning\n",
    "print(\"SENIORITY HYPERPARAMETER OPTIMIZATION\\n\")\n",
    "print(f\"   Train: {len(X_sen_train)} Samples\")\n",
    "print(f\"   Test:  {len(X_sen_test)} Samples\")\n",
    "\n",
    "study_sen = optuna.create_study(direction='maximize')\n",
    "study_sen.optimize(\n",
    "    create_rf_objective(X_sen_train, y_sen_train_enc, X_sen_test, y_sen_test_enc), \n",
    "    n_trials=30, \n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(f\"   Best Params:\")\n",
    "for key, value in study_sen.best_params.items():\n",
    "    print(f\"      {key}: {value}\")\n",
    "\n",
    "# Train finale optimized Seniority Model\n",
    "best_params_sen = study_sen.best_params.copy()\n",
    "best_params_sen['random_state'] = 42\n",
    "best_params_sen['n_jobs'] = -1\n",
    "best_params_sen['bootstrap'] = True\n",
    "\n",
    "rf_sen_final = RandomForestClassifier(**best_params_sen)\n",
    "rf_sen_final.fit(X_sen_train, y_sen_train_enc)\n",
    "\n",
    "# Test Set Evaluation\n",
    "y_sen_final_pred = rf_sen_final.predict(X_sen_test)\n",
    "sen_final_accuracy = accuracy_score(y_sen_test_enc, y_sen_final_pred)\n",
    "sen_final_f1 = f1_score(y_sen_test_enc, y_sen_final_pred, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"\\n{'OPTIMIZED SENIORITY TEST ACCURACY:':<35} {sen_final_accuracy:.4f} ({sen_final_accuracy*100:.2f}%)\")\n",
    "print(f\"{'OPTIMIZED SENIORITY TEST F1-MACRO:':<35} {sen_final_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Optimized Seniority):\")\n",
    "test_labels_sen = sorted(set(y_sen_test_enc))\n",
    "test_names_sen = [le_sen_rf.classes_[i] for i in test_labels_sen]\n",
    "print(classification_report(y_sen_test_enc, y_sen_final_pred, \n",
    "                          labels=test_labels_sen,\n",
    "                          target_names=test_names_sen, \n",
    "                          zero_division=0))\n",
    "\n",
    "# Department Tuning\n",
    "print(\"DEPARTMENT HYPERPARAMETER OPTIMIZATION\\n\")\n",
    "print(f\"   Train: {len(X_dept_train)} Samples\")\n",
    "print(f\"   Test:  {len(X_dept_test)} Samples\")\n",
    "\n",
    "study_dept = optuna.create_study(direction='maximize')\n",
    "study_dept.optimize(\n",
    "    create_rf_objective(X_dept_train, y_dept_train_enc, X_dept_test, y_dept_test_enc), \n",
    "    n_trials=30, \n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"   Best Params:\")\n",
    "for key, value in study_dept.best_params.items():\n",
    "    print(f\"      {key}: {value}\")\n",
    "\n",
    "# Train finale optimized Department Modell\n",
    "best_params_dept = study_dept.best_params.copy()\n",
    "best_params_dept['random_state'] = 42\n",
    "best_params_dept['n_jobs'] = -1\n",
    "best_params_dept['bootstrap'] = True\n",
    "\n",
    "rf_dept_final = RandomForestClassifier(**best_params_dept)\n",
    "rf_dept_final.fit(X_dept_train, y_dept_train_enc)\n",
    "\n",
    "# Test Set Evaluation\n",
    "y_dept_final_pred = rf_dept_final.predict(X_dept_test)\n",
    "dept_final_accuracy = accuracy_score(y_dept_test_enc, y_dept_final_pred)\n",
    "dept_final_f1 = f1_score(y_dept_test_enc, y_dept_final_pred, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"\\n{'OPTIMIZED DEPARTMENT TEST ACCURACY:':<35} {dept_final_accuracy:.4f} ({dept_final_accuracy*100:.2f}%)\")\n",
    "print(f\"{'OPTIMIZED DEPARTMENT TEST F1-MACRO:':<35} {dept_final_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Optimized Department):\")\n",
    "test_labels_dept = sorted(set(y_dept_test_enc))\n",
    "test_names_dept = [le_dept_rf.classes_[i] for i in test_labels_dept]\n",
    "print(classification_report(y_dept_test_enc, y_dept_final_pred,\n",
    "                          labels=test_labels_dept,\n",
    "                          target_names=test_names_dept,\n",
    "                          zero_division=0))\n",
    "\n",
    "# Final Summary\n",
    "\n",
    "print(\"\\nBASELINE vs. OPTIMIZED\")\n",
    "print(f\"{'Modell':<20} {'Baseline Accuracy':<20} {'Optimized Accuracy':<20}\")\n",
    "print(f\"{'Seniority':<20} {sen_accuracy*100:>17.2f}%  {sen_final_accuracy*100:>18.2f}%\")\n",
    "print(f\"{'Department':<20} {dept_accuracy*100:>17.2f}%  {dept_final_accuracy*100:>18.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad309641",
   "metadata": {},
   "source": [
    "## 12 HYBRID PREDICTOR (TF-IDF + RF)\n",
    "1. TF-IDF Prediction:  TF-IDF predictet Label + Confidence\n",
    "2.  Random Forest Prediction: RF predictet Label + Confidence\n",
    "\n",
    "3. Hybrid Combination\n",
    "3a) IF TF-IDF-Conf >= 0.85:\n",
    "      ‚Üí Return TF-IDF-Label\n",
    "  \n",
    "3b) IF RF-Conf >= 0.70:\n",
    "      ‚Üí Return RF-Label\n",
    "  \n",
    "3c) ELSE:\n",
    "    Seniority: ‚Üí Return Label with higher Confidence\n",
    "    Department: IF both Confidences < 0.6: Department Fallback (department of previous job, if a previous job exists)\n",
    "                IF one Conficence > 0.6 or no previous job -> Return label with higher confidence\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e27aa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYBRID PREDICTOR - TF-IDF + RANDOM FOREST\n",
      "\n",
      "\n",
      "Hybrid Configuration\n",
      "  TF-IDF High Confidence:  0.85\n",
      "  RF High Confidence:      0.7\n",
      "  Department Fallback:     True\n"
     ]
    }
   ],
   "source": [
    "print(\"HYBRID PREDICTOR - TF-IDF + RANDOM FOREST\\n\")\n",
    "\n",
    "# Hybrid Configuration\n",
    "@dataclass\n",
    "class HybridConfig:\n",
    "    base_hi: float = 0.85\n",
    "    rf_hi: float = 0.70\n",
    "    dept_fallback: bool = True\n",
    "\n",
    "hybrid_cfg = HybridConfig()\n",
    "\n",
    "print(\"\\nHybrid Configuration\")\n",
    "print(f\"  TF-IDF High Confidence:  {hybrid_cfg.base_hi}\")\n",
    "print(f\"  RF High Confidence:      {hybrid_cfg.rf_hi}\")\n",
    "print(f\"  Department Fallback:     {hybrid_cfg.dept_fallback}\")\n",
    "\n",
    "# Hybrid Predictor Class\n",
    "class HybridPredictorTFIDF:\n",
    "    \"\"\"\n",
    "    Hybrid Model: TF-IDF + Random Forest\n",
    "    TF-IDF f√ºr Text-Robustheit, RF f√ºr Job-Historie Kontext\n",
    "    \"\"\"\n",
    "    def __init__(self, tfidf_model, rf_model, le_rf, is_department, cfg):\n",
    "        self.tfidf_model = tfidf_model\n",
    "        self.rf_model = rf_model\n",
    "        self.le_rf = le_rf\n",
    "        self.is_department = is_department\n",
    "        self.cfg = cfg\n",
    "        self.rf_expected_features = list(self.rf_model.feature_names_in_)\n",
    "    \n",
    "    def predict(self, person_jobs, target_job_idx=0):\n",
    "        job = person_jobs[target_job_idx]\n",
    "        text = str(job.get(\"position\", \"\")).strip()\n",
    "        \n",
    "        # 1. TF-IDF Prediction\n",
    "        tfidf_pred, tfidf_conf = predict_with_confidence(self.tfidf_model, text)\n",
    "        \n",
    "        # 2. Random Forest Prediction\n",
    "        features = extract_job_history_features(person_jobs, target_job_idx)\n",
    "        feature_df = pd.DataFrame([features])\n",
    "        \n",
    "        for feat in self.rf_expected_features:\n",
    "            if feat not in feature_df.columns:\n",
    "                feature_df[feat] = 0\n",
    "        \n",
    "        feature_vector = feature_df[self.rf_expected_features].fillna(0)\n",
    "        \n",
    "        rf_pred_idx = self.rf_model.predict(feature_vector)[0]\n",
    "        rf_probs = self.rf_model.predict_proba(feature_vector)[0]\n",
    "        rf_conf = rf_probs.max()\n",
    "        rf_pred = self.le_rf.inverse_transform([rf_pred_idx])[0]\n",
    "        \n",
    "        # 3. Combination Logic\n",
    "        if tfidf_conf >= self.cfg.base_hi:\n",
    "            return tfidf_pred\n",
    "        if rf_conf >= self.cfg.rf_hi:\n",
    "            return rf_pred\n",
    "        \n",
    "        # 4. Department Fallback (previous Department)\n",
    "        if self.is_department and self.cfg.dept_fallback:\n",
    "            if tfidf_conf < 0.6 and rf_conf < 0.6:\n",
    "                if len(person_jobs) > target_job_idx + 1:\n",
    "                    prev_dept = person_jobs[target_job_idx + 1].get(\"department\")\n",
    "                    if prev_dept:\n",
    "                        return prev_dept\n",
    "        \n",
    "        # 5. Else: Higher Confidence\n",
    "        return tfidf_pred if tfidf_conf >= rf_conf else rf_pred\n",
    "\n",
    "# Create Hybrid Predictors\n",
    "hybrid_sen = HybridPredictorTFIDF(\n",
    "    tfidf_model=sen_TFIDF,\n",
    "    rf_model=rf_sen_final,\n",
    "    le_rf=le_sen_rf,\n",
    "    is_department=False,\n",
    "    cfg=hybrid_cfg\n",
    ")\n",
    "\n",
    "hybrid_dept = HybridPredictorTFIDF(\n",
    "    tfidf_model=dept_TFIDF,\n",
    "    rf_model=rf_dept_final,\n",
    "    le_rf=le_dept_rf,\n",
    "    is_department=True,\n",
    "    cfg=hybrid_cfg\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f7eb52",
   "metadata": {},
   "source": [
    "## 13 LOAD ANNOTATED DATA & FINAL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7071009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINALE EVALUATION - LINKEDIN ANNOTATED DATA\n",
      "\n",
      "   Total jobs: 2638\n",
      "   Active jobs: 623\n",
      "\n",
      "Generiere Predictions auf Annotated Data...\n",
      "Progress: 100/609\n",
      "Progress: 200/609\n",
      "Progress: 300/609\n",
      "Progress: 400/609\n",
      "Progress: 500/609\n",
      "Progress: 600/609\n",
      "   Seniority: 623 jobs\n",
      "   Department: 623 jobs\n"
     ]
    }
   ],
   "source": [
    "print(\"FINALE EVALUATION - LINKEDIN ANNOTATED DATA\\n\")\n",
    "\n",
    "# Load Annotated Data\n",
    "with open('linkedin-cvs-annotated.json', 'r', encoding='utf-8') as f:\n",
    "    annotated = json.load(f)\n",
    "\n",
    "\n",
    "total_jobs = sum(len(person) for person in annotated)\n",
    "active_jobs = sum(1 for person in annotated for job in person if job.get('status') == 'ACTIVE')\n",
    "print(f\"   Total jobs: {total_jobs}\")\n",
    "print(f\"   Active jobs: {active_jobs}\")\n",
    "\n",
    "# Generate Predictions\n",
    "print(\"\\nGeneriere Predictions auf Annotated Data...\")\n",
    "\n",
    "predictions_sen = []\n",
    "predictions_dept = []\n",
    "true_sen = []\n",
    "true_dept = []\n",
    "\n",
    "for person_idx, person_jobs in enumerate(annotated):\n",
    "    if person_idx % 100 == 0 and person_idx > 0:\n",
    "        print(f\"Progress: {person_idx}/{len(annotated)}\")\n",
    "    \n",
    "    for job_idx, job in enumerate(person_jobs):\n",
    "        if job.get('status') == 'ACTIVE':\n",
    "            if job.get('seniority'):\n",
    "                pred_sen = hybrid_sen.predict(person_jobs, job_idx)\n",
    "                predictions_sen.append(pred_sen)\n",
    "                true_sen.append(job['seniority'])\n",
    "            \n",
    "            if job.get('department'):\n",
    "                pred_dept = hybrid_dept.predict(person_jobs, job_idx)\n",
    "                predictions_dept.append(pred_dept)\n",
    "                true_dept.append(job['department'])\n",
    "\n",
    "\n",
    "print(f\"   Seniority: {len(predictions_sen)} jobs\")\n",
    "print(f\"   Department: {len(predictions_dept)} jobs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b3bb4c",
   "metadata": {},
   "source": [
    "## 14 RESULTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6c0e6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION RESULTS\n",
      "\n",
      "\n",
      "SENIORITY - EVALUATION\n",
      "  Accuracy: 0.4671\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Director       0.58      0.91      0.71        34\n",
      "      Junior       0.18      0.25      0.21        12\n",
      "        Lead       0.77      0.52      0.62       125\n",
      "  Management       0.51      0.84      0.63       192\n",
      "Professional       0.00      0.00      0.00       216\n",
      "      Senior       0.20      0.68      0.31        44\n",
      "\n",
      "    accuracy                           0.47       623\n",
      "   macro avg       0.37      0.53      0.41       623\n",
      "weighted avg       0.36      0.47      0.38       623\n",
      "\n",
      "\n",
      "DEPARTMENT - EVALUATION\n",
      "  Accuracy: 0.5714\n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        Administrative       0.21      0.43      0.29        14\n",
      "  Business Development       0.27      0.35      0.30        20\n",
      "            Consulting       0.40      0.44      0.41        39\n",
      "      Customer Support       0.38      0.50      0.43         6\n",
      "       Human Resources       0.58      0.69      0.63        16\n",
      "Information Technology       0.36      0.66      0.46        62\n",
      "             Marketing       0.39      0.50      0.44        22\n",
      "                 Other       0.78      0.55      0.64       344\n",
      "    Project Management       0.60      0.69      0.64        39\n",
      "            Purchasing       0.76      0.87      0.81        15\n",
      "                 Sales       0.60      0.70      0.65        46\n",
      "\n",
      "              accuracy                           0.57       623\n",
      "             macro avg       0.48      0.58      0.52       623\n",
      "          weighted avg       0.64      0.57      0.59       623\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sophia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Sophia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Sophia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "print(\"EVALUATION RESULTS\\n\")\n",
    "\n",
    "# Seniority Evaluation\n",
    "print(\"\\nSENIORITY - EVALUATION\")\n",
    "acc_sen = accuracy_score(true_sen, predictions_sen)\n",
    "print(f\"  Accuracy: {acc_sen:.4f}\")\n",
    "print(\"\\n\" + classification_report(true_sen, predictions_sen))\n",
    "\n",
    "\n",
    "# Department Evaluation\n",
    "print(\"\\nDEPARTMENT - EVALUATION\")\n",
    "acc_dept = accuracy_score(true_dept, predictions_dept)\n",
    "print(f\"  Accuracy: {acc_dept:.4f}\")\n",
    "print(\"\\n\" + classification_report(true_dept, predictions_dept))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509145f1",
   "metadata": {},
   "source": [
    "## 15 Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32cf8e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVE HYBRID MODEL\n",
      " TF-IDF Modelle gespeichert\n",
      " Random Forest Modelle und Label Encoder gespeichert\n",
      " Konfiguration gespeichert\n",
      " Helper Functions gespeichert\n",
      " Hybrid Predictor Class gespeichert\n",
      " __init__.py erstellt (Package)\n",
      "ALLE MODELL-KOMPONENTEN GESPEICHERT\n",
      "\n",
      "Gespeicherte Dateien in 'hybrid_model/':\n",
      "   - tfidf_seniority.pkl\n",
      "   - tfidf_department.pkl\n",
      "   - rf_seniority.pkl\n",
      "   - rf_department.pkl\n",
      "   - le_seniority_rf.pkl\n",
      "   - le_department_rf.pkl\n",
      "   - config.pkl\n",
      "   - model_helpers.py\n",
      "   - hybrid_predictor.py\n",
      "   - __init__.py\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# SAVE HYBRID MODEL FOR DEPLOYMENT\n",
    "\n",
    "print(\"SAVE HYBRID MODEL\")\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('hybrid_model', exist_ok=True)\n",
    "\n",
    "# 1. SAVE TF-IDF MODELS\n",
    "joblib.dump(sen_TFIDF, 'hybrid_model/tfidf_seniority.pkl')\n",
    "joblib.dump(dept_TFIDF, 'hybrid_model/tfidf_department.pkl')\n",
    "print(\" TF-IDF Modelle gespeichert\")\n",
    "\n",
    "# 2. SAVE RANDOM FOREST MODELS + LABEL ENCODERS\n",
    "joblib.dump(rf_sen_final, 'hybrid_model/rf_seniority.pkl')\n",
    "joblib.dump(le_sen_rf, 'hybrid_model/le_seniority_rf.pkl')\n",
    "\n",
    "joblib.dump(rf_dept_final, 'hybrid_model/rf_department.pkl')\n",
    "joblib.dump(le_dept_rf, 'hybrid_model/le_department_rf.pkl')\n",
    "print(\" Random Forest Modelle und Label Encoder gespeichert\")\n",
    "\n",
    "# 3. SAVE CONFIGURATION\n",
    "model_config = {\n",
    "    'hybrid_config': {\n",
    "        'base_hi': hybrid_cfg.base_hi,\n",
    "        'rf_hi': hybrid_cfg.rf_hi,\n",
    "        'dept_fallback': hybrid_cfg.dept_fallback\n",
    "    },\n",
    "    'feature_cols': FEATURE_COLS,\n",
    "    'model_info': {\n",
    "        'seniority_classes': list(le_sen_rf.classes_),\n",
    "        'department_classes': list(le_dept_rf.classes_),\n",
    "        'rf_sen_params': rf_sen_final.get_params(),\n",
    "        'rf_dept_params': rf_dept_final.get_params()\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('hybrid_model/config.pkl', 'wb') as f:\n",
    "    pickle.dump(model_config, f)\n",
    "print(\" Konfiguration gespeichert\")\n",
    "\n",
    "# 4. SAVE HELPER FUNCTIONS AS PYTHON MODULE\n",
    "helper_code = '''\"\"\"\n",
    "Helper Functions f√ºr Hybrid Model Prediction\n",
    "Generiert automatisch beim Training\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def normalize(text):\n",
    "    \"\"\"Text-Normalisierung: Umlaute, Gendering, Sonderzeichen\"\"\"\n",
    "    import re\n",
    "    if text is None or (isinstance(text, float) and pd.isna(text)):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = text.replace(\"√§\",\"ae\").replace(\"√∂\",\"oe\").replace(\"√º\",\"ue\").replace(\"√ü\",\"ss\")\n",
    "    text = re.sub(r\"(innen|in)\\\\b\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z0-9 ]\", \" \", text)\n",
    "    text = re.sub(r\"\\\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def predict_with_confidence(model, text):\n",
    "    \"\"\"TF-IDF Prediction mit Confidence Score\"\"\"\n",
    "    text_norm = normalize(text)\n",
    "    proba = model.predict_proba([text_norm])[0]\n",
    "    pred_idx = int(np.argmax(proba))\n",
    "    pred_label = str(model.classes_[pred_idx])\n",
    "    confidence = float(proba[pred_idx])\n",
    "    return pred_label, confidence\n",
    "\n",
    "def calculate_months_between(start_date, end_date):\n",
    "    \"\"\"Berechnet Monate zwischen zwei Daten\"\"\"\n",
    "    try:\n",
    "        start = pd.to_datetime(start_date)\n",
    "        end = pd.to_datetime(end_date) if end_date else pd.to_datetime(datetime.now())\n",
    "        return float((end - start).days / 30)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def extract_job_history_features(person_jobs, target_job_idx=0):\n",
    "    \"\"\"Extrahiert 24 Features aus Job-Historie\"\"\"\n",
    "    target_job = person_jobs[target_job_idx]\n",
    "    \n",
    "    features = {\n",
    "        'total_jobs': len(person_jobs),\n",
    "        'job_number': target_job_idx + 1,\n",
    "        'previous_seniority_junior': 0,\n",
    "        'previous_seniority_professional': 0,\n",
    "        'previous_seniority_senior': 0,\n",
    "        'previous_seniority_lead': 0,\n",
    "        'previous_seniority_management': 0,\n",
    "        'previous_seniority_director': 0,\n",
    "        'previous_dept_administrative': 0,\n",
    "        'previous_dept_business_dev': 0,\n",
    "        'previous_dept_consulting': 0,\n",
    "        'previous_dept_customer_support': 0,\n",
    "        'previous_dept_hr': 0,\n",
    "        'previous_dept_it': 0,\n",
    "        'previous_dept_marketing': 0,\n",
    "        'previous_dept_other': 0,\n",
    "        'previous_dept_project_mgmt': 0,\n",
    "        'previous_dept_purchasing': 0,\n",
    "        'previous_dept_sales': 0,\n",
    "        'same_department_as_previous': 0,\n",
    "        'months_in_current_job': 0.0,\n",
    "        'avg_job_duration': 0.0,\n",
    "        'seniority_increases': 0,\n",
    "        'department_changes': 0,\n",
    "    }\n",
    "    \n",
    "    # Previous Job Features\n",
    "    if len(person_jobs) > target_job_idx + 1:\n",
    "        prev_job = person_jobs[target_job_idx + 1]\n",
    "        prev_sen = prev_job.get('seniority')\n",
    "        \n",
    "        if prev_sen == 'Junior': features['previous_seniority_junior'] = 1\n",
    "        elif prev_sen == 'Professional': features['previous_seniority_professional'] = 1\n",
    "        elif prev_sen == 'Senior': features['previous_seniority_senior'] = 1\n",
    "        elif prev_sen == 'Lead': features['previous_seniority_lead'] = 1\n",
    "        elif prev_sen == 'Management': features['previous_seniority_management'] = 1\n",
    "        elif prev_sen == 'Director': features['previous_seniority_director'] = 1\n",
    "        \n",
    "        prev_dept = prev_job.get('department')\n",
    "        dept_map = {\n",
    "            'Administrative': 'previous_dept_administrative',\n",
    "            'Business Development': 'previous_dept_business_dev',\n",
    "            'Consulting': 'previous_dept_consulting',\n",
    "            'Customer Support': 'previous_dept_customer_support',\n",
    "            'Human Resources': 'previous_dept_hr',\n",
    "            'Information Technology': 'previous_dept_it',\n",
    "            'Marketing': 'previous_dept_marketing',\n",
    "            'Other': 'previous_dept_other',\n",
    "            'Project Management': 'previous_dept_project_mgmt',\n",
    "            'Purchasing': 'previous_dept_purchasing',\n",
    "            'Sales': 'previous_dept_sales',\n",
    "        }\n",
    "        if prev_dept in dept_map:\n",
    "            features[dept_map[prev_dept]] = 1\n",
    "        \n",
    "        if prev_dept and target_job.get('department') and prev_dept == target_job.get('department'):\n",
    "            features['same_department_as_previous'] = 1\n",
    "    \n",
    "    # Time Features\n",
    "    features['months_in_current_job'] = calculate_months_between(\n",
    "        target_job.get('startDate'), target_job.get('endDate')\n",
    "    )\n",
    "    \n",
    "    durations = []\n",
    "    for job in person_jobs:\n",
    "        dur = calculate_months_between(job.get('startDate'), job.get('endDate'))\n",
    "        if dur > 0:\n",
    "            durations.append(dur)\n",
    "    if durations:\n",
    "        features['avg_job_duration'] = float(np.mean(durations))\n",
    "    \n",
    "    # Progression Features\n",
    "    seniority_order = {\n",
    "        'Junior': 1, 'Professional': 2, 'Senior': 3, \n",
    "        'Lead': 4, 'Management': 5, 'Director': 6\n",
    "    }\n",
    "    for i in range(len(person_jobs) - 1, 0, -1):\n",
    "        older_sen = person_jobs[i].get('seniority')\n",
    "        newer_sen = person_jobs[i-1].get('seniority')\n",
    "        if older_sen and newer_sen:\n",
    "            if seniority_order.get(newer_sen, 0) > seniority_order.get(older_sen, 0):\n",
    "                features['seniority_increases'] += 1\n",
    "    \n",
    "    for i in range(len(person_jobs) - 1):\n",
    "        if person_jobs[i].get('department') != person_jobs[i+1].get('department'):\n",
    "            features['department_changes'] += 1\n",
    "    \n",
    "    return features\n",
    "'''\n",
    "\n",
    "with open('hybrid_model/model_helpers.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(helper_code)\n",
    "print(\" Helper Functions gespeichert\")\n",
    "\n",
    "# 5. CREATE HYBRID PREDICTOR CLASS FILE\n",
    "predictor_code = '''\"\"\"\n",
    "Hybrid Predictor Class f√ºr Streamlit Deployment\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "import sys\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Fix imports - add current directory to path\n",
    "sys.path.insert(0, os.path.dirname(__file__))\n",
    "\n",
    "# Now import helpers\n",
    "from model_helpers import normalize, predict_with_confidence, extract_job_history_features\n",
    "\n",
    "class HybridPredictor:\n",
    "    \"\"\"\n",
    "    Hybrid Model: TF-IDF + Random Forest\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_dir='hybrid_model'):\n",
    "        \"\"\"L√§dt alle Modell-Komponenten\"\"\"\n",
    "        \n",
    "        # Make paths absolute\n",
    "        if not os.path.isabs(model_dir):\n",
    "            model_dir = os.path.join(os.getcwd(), model_dir)\n",
    "        \n",
    "        print(f\"Lade Modelle aus: {model_dir}\")\n",
    "        \n",
    "        # Load TF-IDF Models\n",
    "        self.tfidf_sen = joblib.load(f'{model_dir}/tfidf_seniority.pkl')\n",
    "        self.tfidf_dept = joblib.load(f'{model_dir}/tfidf_department.pkl')\n",
    "        \n",
    "        # Load Random Forest Models\n",
    "        self.rf_sen = joblib.load(f'{model_dir}/rf_seniority.pkl')\n",
    "        self.rf_dept = joblib.load(f'{model_dir}/rf_department.pkl')\n",
    "        \n",
    "        # Load Label Encoders\n",
    "        self.le_sen_rf = joblib.load(f'{model_dir}/le_seniority_rf.pkl')\n",
    "        self.le_dept_rf = joblib.load(f'{model_dir}/le_department_rf.pkl')\n",
    "        \n",
    "        # Load Config\n",
    "        with open(f'{model_dir}/config.pkl', 'rb') as f:\n",
    "            config = pickle.load(f)\n",
    "            self.hybrid_cfg = config['hybrid_config']\n",
    "            self.feature_cols = config['feature_cols']\n",
    "        \n",
    "        # Expected Features\n",
    "        self.rf_sen_features = list(self.rf_sen.feature_names_in_)\n",
    "        self.rf_dept_features = list(self.rf_dept.feature_names_in_)\n",
    "        \n",
    "        print(f\" Modelle geladen\")\n",
    "        print(f\"   Seniority Classes: {list(self.le_sen_rf.classes_)}\")\n",
    "        print(f\"   Department Classes: {list(self.le_dept_rf.classes_)}\")\n",
    "    \n",
    "    def predict_seniority(self, person_jobs: List[Dict], target_job_idx: int = 0) -> Dict[str, Any]:\n",
    "        \"\"\"Predict Seniority f√ºr einen Job\"\"\"\n",
    "        job = person_jobs[target_job_idx]\n",
    "        text = str(job.get(\"position\", \"\")).strip()\n",
    "        \n",
    "        # TF-IDF Prediction\n",
    "        tfidf_pred, tfidf_conf = predict_with_confidence(self.tfidf_sen, text)\n",
    "        \n",
    "        # Random Forest Prediction\n",
    "        features = extract_job_history_features(person_jobs, target_job_idx)\n",
    "        feature_df = pd.DataFrame([features])\n",
    "        \n",
    "        # Ensure all required features exist\n",
    "        for feat in self.rf_sen_features:\n",
    "            if feat not in feature_df.columns:\n",
    "                feature_df[feat] = 0\n",
    "        \n",
    "        feature_vector = feature_df[self.rf_sen_features].fillna(0)\n",
    "        rf_pred_idx = self.rf_sen.predict(feature_vector)[0]\n",
    "        rf_probs = self.rf_sen.predict_proba(feature_vector)[0]\n",
    "        rf_conf = rf_probs.max()\n",
    "        rf_pred = self.le_sen_rf.inverse_transform([rf_pred_idx])[0]\n",
    "        \n",
    "        # Combination Logic\n",
    "        if tfidf_conf >= self.hybrid_cfg['base_hi']:\n",
    "            return {'label': tfidf_pred, 'confidence': tfidf_conf, 'source': 'tfidf'}\n",
    "        if rf_conf >= self.hybrid_cfg['rf_hi']:\n",
    "            return {'label': rf_pred, 'confidence': rf_conf, 'source': 'rf'}\n",
    "        \n",
    "        # Else: Higher confidence wins\n",
    "        if tfidf_conf >= rf_conf:\n",
    "            return {'label': tfidf_pred, 'confidence': tfidf_conf, 'source': 'tfidf_fallback'}\n",
    "        else:\n",
    "            return {'label': rf_pred, 'confidence': rf_conf, 'source': 'rf_fallback'}\n",
    "    \n",
    "    def predict_department(self, person_jobs: List[Dict], target_job_idx: int = 0) -> Dict[str, Any]:\n",
    "        \"\"\"Predict Department f√ºr einen Job\"\"\"\n",
    "        job = person_jobs[target_job_idx]\n",
    "        text = str(job.get(\"position\", \"\")).strip()\n",
    "        \n",
    "        # TF-IDF Prediction\n",
    "        tfidf_pred, tfidf_conf = predict_with_confidence(self.tfidf_dept, text)\n",
    "        \n",
    "        # Random Forest Prediction\n",
    "        features = extract_job_history_features(person_jobs, target_job_idx)\n",
    "        feature_df = pd.DataFrame([features])\n",
    "        \n",
    "        # Ensure all required features exist\n",
    "        for feat in self.rf_dept_features:\n",
    "            if feat not in feature_df.columns:\n",
    "                feature_df[feat] = 0\n",
    "        \n",
    "        feature_vector = feature_df[self.rf_dept_features].fillna(0)\n",
    "        rf_pred_idx = self.rf_dept.predict(feature_vector)[0]\n",
    "        rf_probs = self.rf_dept.predict_proba(feature_vector)[0]\n",
    "        rf_conf = rf_probs.max()\n",
    "        rf_pred = self.le_dept_rf.inverse_transform([rf_pred_idx])[0]\n",
    "        \n",
    "        # Combination Logic\n",
    "        if tfidf_conf >= self.hybrid_cfg['base_hi']:\n",
    "            return {'label': tfidf_pred, 'confidence': tfidf_conf, 'source': 'tfidf'}\n",
    "        if rf_conf >= self.hybrid_cfg['rf_hi']:\n",
    "            return {'label': rf_pred, 'confidence': rf_conf, 'source': 'rf'}\n",
    "        \n",
    "        # Department Fallback: Use previous job if both confidences are low\n",
    "        if self.hybrid_cfg['dept_fallback'] and tfidf_conf < 0.6 and rf_conf < 0.6:\n",
    "            if len(person_jobs) > target_job_idx + 1:\n",
    "                prev_dept = person_jobs[target_job_idx + 1].get(\"department\")\n",
    "                if prev_dept:\n",
    "                    return {'label': prev_dept, 'confidence': 0.5, 'source': 'previous_job'}\n",
    "        \n",
    "        # Else: Higher confidence wins\n",
    "        if tfidf_conf >= rf_conf:\n",
    "            return {'label': tfidf_pred, 'confidence': tfidf_conf, 'source': 'tfidf_fallback'}\n",
    "        else:\n",
    "            return {'label': rf_pred, 'confidence': rf_conf, 'source': 'rf_fallback'}\n",
    "    \n",
    "    def predict(self, person_jobs: List[Dict], target_job_idx: int = 0) -> Dict[str, Any]:\n",
    "        \"\"\"Predict beide Tasks f√ºr einen Job\"\"\"\n",
    "        sen_result = self.predict_seniority(person_jobs, target_job_idx)\n",
    "        dept_result = self.predict_department(person_jobs, target_job_idx)\n",
    "        \n",
    "        return {\n",
    "            'seniority': sen_result,\n",
    "            'department': dept_result\n",
    "        }\n",
    "'''\n",
    "\n",
    "with open('hybrid_model/hybrid_predictor.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(predictor_code)\n",
    "print(\" Hybrid Predictor Class gespeichert\")\n",
    "\n",
    "# 6. CREATE __init__.py (MAKES IT A PROPER PACKAGE)\n",
    "init_code = '''\"\"\"\n",
    "Hybrid Model Package f√ºr LinkedIn Job Classification\n",
    "\"\"\"\n",
    "\n",
    "from .hybrid_predictor import HybridPredictor\n",
    "\n",
    "__all__ = ['HybridPredictor']\n",
    "__version__ = '1.0.0'\n",
    "'''\n",
    "\n",
    "with open('hybrid_model/__init__.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(init_code)\n",
    "print(\" __init__.py erstellt (Package)\")\n",
    "\n",
    "\n",
    "print(\"ALLE MODELL-KOMPONENTEN GESPEICHERT\")\n",
    "\n",
    "print(f\"\\nGespeicherte Dateien in 'hybrid_model/':\")\n",
    "print(\"   - tfidf_seniority.pkl\")\n",
    "print(\"   - tfidf_department.pkl\")\n",
    "print(\"   - rf_seniority.pkl\")\n",
    "print(\"   - rf_department.pkl\")\n",
    "print(\"   - le_seniority_rf.pkl\")\n",
    "print(\"   - le_department_rf.pkl\")\n",
    "print(\"   - config.pkl\")\n",
    "print(\"   - model_helpers.py\")\n",
    "print(\"   - hybrid_predictor.py\")\n",
    "print(\"   - __init__.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
