{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7342127c",
   "metadata": {},
   "source": [
    "## Approach 6 (Baseline) **and then** Approach 6 + 5 (Hybrid)\n",
    "Order:\n",
    "1) **Approach 6 only**: TF–IDF (char n-grams) + Logistic Regression aus CSVs → Evaluation on `annotated.json` (Original)\n",
    "2) **Approach 6 + 5**: RuleLabeler + Agreement Pseudo-Labels auf `not_annotated.json` → RF (Optuna) + Hybrid → Evaluation on `annotated.json` (Original + Fair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f037d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84628ab",
   "metadata": {},
   "source": [
    "### 1) Config / Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cbd688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paths(seniority_csv='seniority-v2.csv', department_csv='department-v2.csv', not_annotated_json='linkedin-cvs-not-annotated.json', annotated_json='linkedin-cvs-annotated.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class Paths:\n",
    "    seniority_csv: str = \"seniority-v2.csv\"\n",
    "    department_csv: str = \"department-v2.csv\"\n",
    "    not_annotated_json: str = \"linkedin-cvs-not-annotated.json\"\n",
    "    annotated_json: str = \"linkedin-cvs-annotated.json\"\n",
    "\n",
    "@dataclass\n",
    "class PseudoConfig:\n",
    "    # Agreement pseudo-labels without calibration:\n",
    "    base_hi: float = 0.85          # baseline very confident -> accept\n",
    "    base_agree_min: float = 0.60   # if baseline == rule -> accept from here\n",
    "\n",
    "    # Person Filter:\n",
    "    min_keep_ratio: float = 0.80\n",
    "    min_conf_for_person: float = 0.60\n",
    "\n",
    "    only_active: bool = True\n",
    "\n",
    "@dataclass\n",
    "class HybridConfig:\n",
    "    base_hi: float = 0.85\n",
    "    rf_hi: float = 0.70\n",
    "    dept_fallback: bool = True\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    random_state: int = 42\n",
    "\n",
    "paths = Paths()\n",
    "pseudo_cfg = PseudoConfig()\n",
    "hybrid_cfg = HybridConfig()\n",
    "train_cfg = TrainConfig()\n",
    "\n",
    "paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99bfaf4",
   "metadata": {},
   "source": [
    "### 2) Helpers (Load + Normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70343e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path: str) -> List[List[Dict[str, Any]]]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_label_csv(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    if \"text\" not in df.columns or \"label\" not in df.columns:\n",
    "        raise ValueError(f\"{path}: Erwartet Spalten 'text' und 'label'\")\n",
    "    return df\n",
    "\n",
    "def normalize(text: Any) -> str:\n",
    "    if text is None or (isinstance(text, float) and pd.isna(text)):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = (text.replace(\"ä\",\"ae\").replace(\"ö\",\"oe\").replace(\"ü\",\"ue\").replace(\"ß\",\"ss\"))\n",
    "    text = re.sub(r\"(innen|in)\\b\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z0-9 ]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12100bb",
   "metadata": {},
   "source": [
    "## Part A — Approach 6 (Baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2023a",
   "metadata": {},
   "source": [
    "### 3) Baseline Training (TF-IDF char + LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be40e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline_text_model(df: pd.DataFrame, use_char_ngrams: bool = True) -> Pipeline:\n",
    "    if use_char_ngrams:\n",
    "        vec = TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5), lowercase=True)\n",
    "    else:\n",
    "        vec = TfidfVectorizer(ngram_range=(1,2), lowercase=True)  # word n-grams\n",
    "\n",
    "    clf = LogisticRegression(max_iter=3000, class_weight=\"balanced\")\n",
    "    pipe = Pipeline([(\"tfidf\", vec), (\"clf\", clf)])\n",
    "\n",
    "    X = df[\"text\"].astype(str).map(normalize)\n",
    "    y = df[\"label\"].astype(str)\n",
    "    pipe.fit(X, y)\n",
    "    return pipe\n",
    "\n",
    "def baseline_predict_label_conf(model: Pipeline, text: str) -> Tuple[str, float]:\n",
    "    x = normalize(text)\n",
    "    proba = model.predict_proba([x])[0]\n",
    "    i = int(np.argmax(proba))\n",
    "    return str(model.classes_[i]), float(proba[i])\n",
    "\n",
    "def baseline_predict_label(model: Pipeline, text: str) -> str:\n",
    "    return baseline_predict_label_conf(model, text)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91b073f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sen classes: ['Director' 'Junior' 'Lead' 'Management' 'Senior']\n",
      "Dept classes: ['Administrative' 'Business Development' 'Consulting' 'Customer Support'\n",
      " 'Human Resources' 'Information Technology' 'Marketing' 'Other'\n",
      " 'Project Management' 'Purchasing' 'Sales']\n"
     ]
    }
   ],
   "source": [
    "df_sen = load_label_csv(paths.seniority_csv)\n",
    "df_dept = load_label_csv(paths.department_csv)\n",
    "\n",
    "sen_baseline = train_baseline_text_model(df_sen)\n",
    "dept_baseline = train_baseline_text_model(df_dept)\n",
    "\n",
    "print(\"Sen classes:\", sen_baseline.classes_)\n",
    "print(\"Dept classes:\", dept_baseline.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ec24e",
   "metadata": {},
   "source": [
    "### 4) Baseline Evaluation auf annotated (Original + Fair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2354a406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ANSATZ 6 (Baseline) — ORIGINAL\n",
      "======================================================================\n",
      "\n",
      "SENIORITY (original)\n",
      "Accuracy: 0.478330658105939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Director       0.56      0.97      0.71        34\n",
      "      Junior       0.20      0.33      0.25        12\n",
      "        Lead       0.49      0.73      0.59       125\n",
      "  Management       0.71      0.70      0.70       192\n",
      "Professional       0.00      0.00      0.00       216\n",
      "      Senior       0.21      0.80      0.33        44\n",
      "\n",
      "    accuracy                           0.48       623\n",
      "   macro avg       0.36      0.59      0.43       623\n",
      "weighted avg       0.37      0.48      0.40       623\n",
      "\n",
      "\n",
      "DEPARTMENT (original)\n",
      "Accuracy: 0.2696629213483146\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        Administrative       0.07      0.21      0.11        14\n",
      "  Business Development       0.38      0.30      0.33        20\n",
      "            Consulting       0.87      0.51      0.65        39\n",
      "      Customer Support       0.33      0.17      0.22         6\n",
      "       Human Resources       0.69      0.56      0.62        16\n",
      "Information Technology       0.13      0.85      0.23        62\n",
      "             Marketing       0.38      0.41      0.39        22\n",
      "                 Other       0.50      0.01      0.02       344\n",
      "    Project Management       0.69      0.64      0.67        39\n",
      "            Purchasing       1.00      0.40      0.57        15\n",
      "                 Sales       0.66      0.72      0.69        46\n",
      "\n",
      "              accuracy                           0.27       623\n",
      "             macro avg       0.52      0.44      0.41       623\n",
      "          weighted avg       0.51      0.27      0.22       623\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ANSATZ 6 (Baseline) — FAIR\n",
      "======================================================================\n",
      "\n",
      "SENIORITY (fair): Professional korrekt, wenn Junior oder Senior vorhergesagt\n",
      "Accuracy: 0.6324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Director       0.56      0.97      0.71        34\n",
      "      Junior       0.44      0.33      0.38        12\n",
      "        Lead       0.49      0.73      0.59       125\n",
      "  Management       0.71      0.70      0.70       192\n",
      "Professional       1.00      0.44      0.62       216\n",
      "      Senior       0.42      0.80      0.55        44\n",
      "\n",
      "    accuracy                           0.63       623\n",
      "   macro avg       0.60      0.66      0.59       623\n",
      "weighted avg       0.73      0.63      0.63       623\n",
      "\n",
      "\n",
      "DEPARTMENT (fair): 'Other' ausgeschlossen\n",
      "Evaluiert auf 279/623 Jobs\n",
      "Accuracy: 0.5914\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        Administrative       0.50      0.21      0.30        14\n",
      "  Business Development       0.55      0.30      0.39        20\n",
      "            Consulting       0.95      0.51      0.67        39\n",
      "      Customer Support       1.00      0.17      0.29         6\n",
      "       Human Resources       0.75      0.56      0.64        16\n",
      "Information Technology       0.40      0.85      0.54        62\n",
      "             Marketing       0.60      0.41      0.49        22\n",
      "                 Other       0.00      0.00      0.00         0\n",
      "    Project Management       0.81      0.64      0.71        39\n",
      "            Purchasing       1.00      0.40      0.57        15\n",
      "                 Sales       0.82      0.72      0.77        46\n",
      "\n",
      "              accuracy                           0.59       279\n",
      "             macro avg       0.67      0.43      0.49       279\n",
      "          weighted avg       0.70      0.59      0.60       279\n",
      "\n",
      "\n",
      "======================================================================\n",
      "VERGLEICH: Original vs Fair\n",
      "======================================================================\n",
      "             Metric  Original     Fair\n",
      " Seniority Accuracy  0.478331 0.632424\n",
      "Department Accuracy  0.269663 0.591398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haqu0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\haqu0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\haqu0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\haqu0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\haqu0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\haqu0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6324237560192616, 0.5913978494623656)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collect_predictions_on_annotated_with_model(annotated, sen_model: Pipeline, dept_model: Pipeline):\n",
    "    true_sen, pred_sen_list = [], []\n",
    "    true_dept, pred_dept_list = [], []\n",
    "\n",
    "    for person_jobs in annotated:\n",
    "        for idx, job in enumerate(person_jobs):\n",
    "            if job.get(\"status\") != \"ACTIVE\":\n",
    "                continue\n",
    "            if job.get(\"seniority\") is None or job.get(\"department\") is None:\n",
    "                continue\n",
    "\n",
    "            pos = str(job.get(\"position\", \"\"))\n",
    "\n",
    "            true_sen.append(str(job[\"seniority\"]))\n",
    "            true_dept.append(str(job[\"department\"]))\n",
    "\n",
    "            pred_sen_list.append(baseline_predict_label(sen_model, pos))\n",
    "            pred_dept_list.append(baseline_predict_label(dept_model, pos))\n",
    "\n",
    "    return true_sen, pred_sen_list, true_dept, pred_dept_list\n",
    "\n",
    "def evaluate_original(true_sen, pred_sen_list, true_dept, pred_dept_list, title=\"EVALUATION\"):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(title)\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    print(\"\\nSENIORITY (original)\")\n",
    "    print(\"Accuracy:\", accuracy_score(true_sen, pred_sen_list))\n",
    "    print(classification_report(true_sen, pred_sen_list))\n",
    "\n",
    "    print(\"\\nDEPARTMENT (original)\")\n",
    "    print(\"Accuracy:\", accuracy_score(true_dept, pred_dept_list))\n",
    "    print(classification_report(true_dept, pred_dept_list))\n",
    "\n",
    "def fair_evaluation(true_sen, pred_sen_list, true_dept, pred_dept_list, title=\"FAIRE EVALUATION\"):\n",
    "    # Seniority fair: \n",
    "    true_sen_adjusted, pred_sen_adjusted = [], []\n",
    "    for t, p in zip(true_sen, pred_sen_list):\n",
    "        if t == \"Professional\" and p in [\"Junior\", \"Senior\"]:\n",
    "            true_sen_adjusted.append(\"Professional\")\n",
    "            pred_sen_adjusted.append(\"Professional\")\n",
    "        else:\n",
    "            true_sen_adjusted.append(t)\n",
    "            pred_sen_adjusted.append(p)\n",
    "\n",
    "    acc_sen_fair = accuracy_score(true_sen_adjusted, pred_sen_adjusted)\n",
    "\n",
    "    # Department fair: Other rausfiltern\n",
    "    true_dept_filtered, pred_dept_filtered = [], []\n",
    "    for t, p in zip(true_dept, pred_dept_list):\n",
    "        if t != \"Other\":\n",
    "            true_dept_filtered.append(t)\n",
    "            pred_dept_filtered.append(p)\n",
    "\n",
    "    acc_dept_fair = accuracy_score(true_dept_filtered, pred_dept_filtered)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(title)\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    print(\"\\nSENIORITY (fair): Professional korrekt, wenn Junior oder Senior vorhergesagt\")\n",
    "    print(f\"Accuracy: {acc_sen_fair:.4f}\")\n",
    "    print(classification_report(true_sen_adjusted, pred_sen_adjusted))\n",
    "\n",
    "    print(\"\\nDEPARTMENT (fair): 'Other' ausgeschlossen\")\n",
    "    print(f\"Evaluiert auf {len(true_dept_filtered)}/{len(true_dept)} Jobs\")\n",
    "    print(f\"Accuracy: {acc_dept_fair:.4f}\")\n",
    "    print(classification_report(true_dept_filtered, pred_dept_filtered))\n",
    "\n",
    "    comparison = pd.DataFrame({\n",
    "        \"Metric\": [\"Seniority Accuracy\", \"Department Accuracy\"],\n",
    "        \"Original\": [accuracy_score(true_sen, pred_sen_list), accuracy_score(true_dept, pred_dept_list)],\n",
    "        \"Fair\": [acc_sen_fair, acc_dept_fair],\n",
    "    })\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"VERGLEICH: Original vs Fair\")\n",
    "    print(\"=\"*70)\n",
    "    print(comparison.to_string(index=False))\n",
    "\n",
    "    return acc_sen_fair, acc_dept_fair\n",
    "\n",
    "annotated = load_json(paths.annotated_json)\n",
    "\n",
    "true_sen_6, pred_sen_6, true_dept_6, pred_dept_6 = collect_predictions_on_annotated_with_model(\n",
    "    annotated, sen_baseline, dept_baseline\n",
    ")\n",
    "\n",
    "evaluate_original(true_sen_6, pred_sen_6, true_dept_6, pred_dept_6, title=\"ANSATZ 6 (Baseline) — ORIGINAL\")\n",
    "fair_evaluation(true_sen_6, pred_sen_6, true_dept_6, pred_dept_6, title=\"ANSATZ 6 (Baseline) — FAIR\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c2170",
   "metadata": {},
   "source": [
    "## Part B — Approach 6 + 5 (Hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8212db4f",
   "metadata": {},
   "source": [
    "### 5) RuleLabeler (Approach 5-Component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2a5d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set([\"and\",\"of\",\"for\",\"und\",\"der\",\"die\",\"das\",\"in\",\"mit\",\"to\",\"de\",\"la\",\"le\",\"des\",\"et\",\"en\",\"as\"])\n",
    "\n",
    "SENIORITY_ABBR = {\"jr\":\"Junior\",\"sr\":\"Senior\",\"lead\":\"Lead\",\"chief\":\"Lead\",\"dir\":\"Director\",\"vp\":\"Director\",\"mgr\":\"Management\"}\n",
    "DEPARTMENT_ABBR = {\"it\":\"Information Technology\",\"hr\":\"Human Resources\",\"bd\":\"Business Development\",\"ops\":\"Operations\"}\n",
    "\n",
    "C_LEVEL_ABBR = {\n",
    "    \"CEO\":\"Chief Executive Officer\",\"CFO\":\"Chief Financial Officer\",\"COO\":\"Chief Operating Officer\",\n",
    "    \"CTO\":\"Chief Technology Officer\",\"CMO\":\"Chief Marketing Officer\",\"CIO\":\"Chief Information Officer\",\n",
    "    \"CHRO\":\"Chief Human Resources Officer\",\"EVP\":\"Executive Vice President\",\"SVP\":\"Senior Vice President\",\n",
    "    \"VP\":\"Vice President\",\"AVP\":\"Assistant / Associate Vice President\",\n",
    "}\n",
    "\n",
    "def build_keyword_dict(df: pd.DataFrame) -> Dict[str, Dict[str, int]]:\n",
    "    label_words: Dict[str, List[str]] = defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        lab = str(row[\"label\"])\n",
    "        txt = normalize(row[\"text\"])\n",
    "        for w in txt.split():\n",
    "            if len(w) >= 3 and w not in STOPWORDS:\n",
    "                label_words[lab].append(w)\n",
    "    return {lab: dict(Counter(words).most_common(30)) for lab, words in label_words.items()}\n",
    "\n",
    "def vote(labels: List[Optional[str]]) -> Optional[str]:\n",
    "    labels = [l for l in labels if l is not None]\n",
    "    return Counter(labels).most_common(1)[0][0] if labels else None\n",
    "\n",
    "def length_based_seniority(pos_norm: str) -> Optional[str]:\n",
    "    n = len(pos_norm.split())\n",
    "    if n <= 3: return \"Junior\"\n",
    "    if n >= 6: return \"Senior\"\n",
    "    return None\n",
    "\n",
    "class RuleLabeler:\n",
    "    def __init__(self, df_sen: pd.DataFrame, df_dept: pd.DataFrame):\n",
    "        ds = df_sen.copy()\n",
    "        dd = df_dept.copy()\n",
    "        ds[\"text_clean\"] = ds[\"text\"].map(normalize)\n",
    "        dd[\"text_clean\"] = dd[\"text\"].map(normalize)\n",
    "        self.sen_lookup = dict(zip(ds[\"text_clean\"], ds[\"label\"]))\n",
    "        self.dept_lookup = dict(zip(dd[\"text_clean\"], dd[\"label\"]))\n",
    "        self.sen_keywords = build_keyword_dict(df_sen)\n",
    "        self.dept_keywords = build_keyword_dict(df_dept)\n",
    "\n",
    "    def label_position(self, position: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "        pos = normalize(position)\n",
    "        sen_votes: List[Optional[str]] = [self.sen_lookup.get(pos)]\n",
    "        dept_votes: List[Optional[str]] = [self.dept_lookup.get(pos)]\n",
    "\n",
    "        for lab, kws in self.sen_keywords.items():\n",
    "            for kw in kws.keys():\n",
    "                if kw in pos: sen_votes.append(lab)\n",
    "        for lab, kws in self.dept_keywords.items():\n",
    "            for kw in kws.keys():\n",
    "                if kw in pos: dept_votes.append(lab)\n",
    "\n",
    "        for abbr, lab in SENIORITY_ABBR.items():\n",
    "            if abbr in pos: sen_votes.append(lab)\n",
    "        for abbr, lab in DEPARTMENT_ABBR.items():\n",
    "            if abbr in pos: dept_votes.append(lab)\n",
    "\n",
    "        for abbr, long in C_LEVEL_ABBR.items():\n",
    "            if abbr.lower() in pos or long.lower() in pos:\n",
    "                sen_votes.append(\"Management\")\n",
    "\n",
    "        len_vote = length_based_seniority(pos)\n",
    "        if all(v is None for v in sen_votes):\n",
    "            sen_votes.append(len_vote)\n",
    "\n",
    "        final_sen = vote(sen_votes)\n",
    "        final_dept = vote(dept_votes) or \"Other\"\n",
    "        return final_sen, final_dept\n",
    "\n",
    "rule_labeler = RuleLabeler(df_sen, df_dept)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38107f6",
   "metadata": {},
   "source": [
    "### 6) Agreement Pseudo-Labeling on not_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a9df898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pseudo_label_job_agreement(\n",
    "    job: Dict[str, Any],\n",
    "    sen_model: Pipeline,\n",
    "    dept_model: Pipeline,\n",
    "    rule_labeler: RuleLabeler,\n",
    "    cfg: PseudoConfig\n",
    ") -> Dict[str, Any]:\n",
    "    out = dict(job)\n",
    "    pos = str(job.get(\"position\",\"\")).strip()\n",
    "\n",
    "    sen_pred, sen_conf = baseline_predict_label_conf(sen_model, pos)\n",
    "    dept_pred, dept_conf = baseline_predict_label_conf(dept_model, pos)\n",
    "\n",
    "    r_sen, r_dept = rule_labeler.label_position(pos)\n",
    "\n",
    "    sen_label = None\n",
    "    dept_label = None\n",
    "\n",
    "    if sen_conf >= cfg.base_hi:\n",
    "        sen_label = sen_pred\n",
    "        sen_src = \"base_hi\"\n",
    "    elif (r_sen is not None) and (sen_pred == r_sen) and (sen_conf >= cfg.base_agree_min):\n",
    "        sen_label = sen_pred\n",
    "        sen_src = \"agree_rule\"\n",
    "    else:\n",
    "        sen_src = None\n",
    "\n",
    "    if dept_conf >= cfg.base_hi:\n",
    "        dept_label = dept_pred\n",
    "        dept_src = \"base_hi\"\n",
    "    elif (r_dept is not None) and (dept_pred == r_dept) and (dept_conf >= cfg.base_agree_min):\n",
    "        dept_label = dept_pred\n",
    "        dept_src = \"agree_rule\"\n",
    "    else:\n",
    "        dept_src = None\n",
    "\n",
    "    out[\"seniority\"] = sen_label\n",
    "    out[\"department\"] = dept_label\n",
    "    out[\"confidence_sen\"] = float(sen_conf)\n",
    "    out[\"confidence_dept\"] = float(dept_conf)\n",
    "    out[\"pseudo_source_sen\"] = sen_src\n",
    "    out[\"pseudo_source_dept\"] = dept_src\n",
    "    return out\n",
    "\n",
    "def pseudo_label_dataset_agreement(data, sen_model, dept_model, rule_labeler, cfg: PseudoConfig):\n",
    "    labeled = []\n",
    "    for person_jobs in data:\n",
    "        pj = []\n",
    "        for job in person_jobs:\n",
    "            if cfg.only_active and job.get(\"status\") != \"ACTIVE\":\n",
    "                pj.append(dict(job))\n",
    "            else:\n",
    "                pj.append(pseudo_label_job_agreement(job, sen_model, dept_model, rule_labeler, cfg))\n",
    "        labeled.append(pj)\n",
    "    return labeled\n",
    "\n",
    "not_annotated = load_json(paths.not_annotated_json)\n",
    "\n",
    "pseudo_all = pseudo_label_dataset_agreement(\n",
    "    data=not_annotated,\n",
    "    sen_model=sen_baseline,\n",
    "    dept_model=dept_baseline,\n",
    "    rule_labeler=rule_labeler,\n",
    "    cfg=pseudo_cfg\n",
    ")\n",
    "\n",
    "(len(pseudo_all), len(pseudo_all[0]) if pseudo_all else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe2b51",
   "metadata": {},
   "source": [
    "### 7) Person Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d5a3e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept persons: 41/390 (10.5%)\n"
     ]
    }
   ],
   "source": [
    "def filter_persons_by_confidence(labeled_data, min_confidence, min_keep_ratio, only_active=True):\n",
    "    filtered = []\n",
    "    for person_jobs in labeled_data:\n",
    "        considered = [j for j in person_jobs if (not only_active) or j.get(\"status\") == \"ACTIVE\"]\n",
    "        total = len(considered)\n",
    "        if total == 0:\n",
    "            continue\n",
    "\n",
    "        ok = 0\n",
    "        for j in considered:\n",
    "            cs = float(j.get(\"confidence_sen\", 0))\n",
    "            cd = float(j.get(\"confidence_dept\", 0))\n",
    "            if cs >= min_confidence and cd >= min_confidence and j.get(\"seniority\") and j.get(\"department\"):\n",
    "                ok += 1\n",
    "\n",
    "        if (ok / total) >= min_keep_ratio:\n",
    "            filtered.append(person_jobs)\n",
    "    return filtered\n",
    "\n",
    "pseudo_filtered = filter_persons_by_confidence(\n",
    "    pseudo_all,\n",
    "    min_confidence=pseudo_cfg.min_conf_for_person,\n",
    "    min_keep_ratio=pseudo_cfg.min_keep_ratio,\n",
    "    only_active=pseudo_cfg.only_active\n",
    ")\n",
    "\n",
    "print(f\"Kept persons: {len(pseudo_filtered)}/{len(pseudo_all)} ({len(pseudo_filtered)/max(1,len(pseudo_all))*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4148ca6d",
   "metadata": {},
   "source": [
    "### 8) Features from Job-Historie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc6e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_months_between(start_date: Any, end_date: Any) -> float:\n",
    "    try:\n",
    "        start = pd.to_datetime(start_date)\n",
    "        end = pd.to_datetime(end_date)\n",
    "        return float((end - start).days / 30)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def extract_job_history_features(person_jobs: List[Dict[str, Any]], target_job_idx: int = 0) -> Dict[str, Any]:\n",
    "    target_job = person_jobs[target_job_idx]\n",
    "\n",
    "    feats: Dict[str, Any] = {\n",
    "        \"total_jobs\": len(person_jobs),\n",
    "        \"job_number\": target_job_idx + 1,\n",
    "\n",
    "        \"previous_seniority_junior\": 0,\n",
    "        \"previous_seniority_senior\": 0,\n",
    "        \"previous_seniority_lead\": 0,\n",
    "        \"previous_seniority_management\": 0,\n",
    "        \"previous_seniority_director\": 0,\n",
    "\n",
    "        \"previous_dept_administrative\": 0,\n",
    "        \"previous_dept_business_dev\": 0,\n",
    "        \"previous_dept_consulting\": 0,\n",
    "        \"previous_dept_customer_support\": 0,\n",
    "        \"previous_dept_hr\": 0,\n",
    "        \"previous_dept_it\": 0,\n",
    "        \"previous_dept_marketing\": 0,\n",
    "        \"previous_dept_other\": 0,\n",
    "        \"previous_dept_project_mgmt\": 0,\n",
    "        \"previous_dept_purchasing\": 0,\n",
    "        \"previous_dept_sales\": 0,\n",
    "\n",
    "        \"same_department_as_previous\": 0,\n",
    "\n",
    "        \"months_in_current_job\": calculate_months_between(target_job.get(\"startDate\"), target_job.get(\"endDate\") or datetime.now()),\n",
    "        \"avg_job_duration\": 0.0,\n",
    "\n",
    "        \"seniority_increases\": 0,\n",
    "        \"department_changes\": 0,\n",
    "    }\n",
    "\n",
    "    durs = [calculate_months_between(j.get(\"startDate\"), j.get(\"endDate\") or datetime.now()) for j in person_jobs]\n",
    "    feats[\"avg_job_duration\"] = float(np.mean(durs)) if durs else 0.0\n",
    "\n",
    "    # previous job = idx+1 (correct when list newest->oldest)\n",
    "    if len(person_jobs) > target_job_idx + 1:\n",
    "        prev = person_jobs[target_job_idx + 1]\n",
    "        ps = prev.get(\"seniority\")\n",
    "        pdp = prev.get(\"department\")\n",
    "\n",
    "        if ps == \"Junior\": feats[\"previous_seniority_junior\"] = 1\n",
    "        elif ps == \"Senior\": feats[\"previous_seniority_senior\"] = 1\n",
    "        elif ps == \"Lead\": feats[\"previous_seniority_lead\"] = 1\n",
    "        elif ps == \"Management\": feats[\"previous_seniority_management\"] = 1\n",
    "        elif ps == \"Director\": feats[\"previous_seniority_director\"] = 1\n",
    "\n",
    "        dept_map = {\n",
    "            \"Administrative\": \"previous_dept_administrative\",\n",
    "            \"Business Development\": \"previous_dept_business_dev\",\n",
    "            \"Consulting\": \"previous_dept_consulting\",\n",
    "            \"Customer Support\": \"previous_dept_customer_support\",\n",
    "            \"Human Resources\": \"previous_dept_hr\",\n",
    "            \"Information Technology\": \"previous_dept_it\",\n",
    "            \"Marketing\": \"previous_dept_marketing\",\n",
    "            \"Other\": \"previous_dept_other\",\n",
    "            \"Project Management\": \"previous_dept_project_mgmt\",\n",
    "            \"Purchasing\": \"previous_dept_purchasing\",\n",
    "            \"Sales\": \"previous_dept_sales\",\n",
    "        }\n",
    "        if pdp in dept_map:\n",
    "            feats[dept_map[pdp]] = 1\n",
    "\n",
    "        if pdp and target_job.get(\"department\") and pdp == target_job.get(\"department\"):\n",
    "            feats[\"same_department_as_previous\"] = 1\n",
    "\n",
    "    order = {\"Junior\": 1, \"Senior\": 2, \"Lead\": 3, \"Management\": 4, \"Director\": 5}\n",
    "    prev_s, prev_d = None, None\n",
    "    for j in person_jobs:\n",
    "        s = j.get(\"seniority\")\n",
    "        d = j.get(\"department\")\n",
    "        if prev_s and s and order.get(s, 0) > order.get(prev_s, 0):\n",
    "            feats[\"seniority_increases\"] += 1\n",
    "        if prev_d and d and d != prev_d:\n",
    "            feats[\"department_changes\"] += 1\n",
    "        prev_s, prev_d = s, d\n",
    "\n",
    "    return feats\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    \"total_jobs\",\"job_number\",\n",
    "    \"previous_seniority_junior\",\"previous_seniority_senior\",\"previous_seniority_lead\",\n",
    "    \"previous_seniority_management\",\"previous_seniority_director\",\n",
    "    \"previous_dept_administrative\",\"previous_dept_business_dev\",\"previous_dept_consulting\",\n",
    "    \"previous_dept_customer_support\",\"previous_dept_hr\",\"previous_dept_it\",\n",
    "    \"previous_dept_marketing\",\"previous_dept_other\",\"previous_dept_project_mgmt\",\n",
    "    \"previous_dept_purchasing\",\"previous_dept_sales\",\n",
    "    \"same_department_as_previous\",\n",
    "    \"months_in_current_job\",\"avg_job_duration\",\n",
    "    \"seniority_increases\",\"department_changes\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5948939d",
   "metadata": {},
   "source": [
    "### 9) RF Trainingsdaten bauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "844d23b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF sen rows: 42\n",
      "RF dept rows: 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_jobs</th>\n",
       "      <th>job_number</th>\n",
       "      <th>previous_seniority_junior</th>\n",
       "      <th>previous_seniority_senior</th>\n",
       "      <th>previous_seniority_lead</th>\n",
       "      <th>previous_seniority_management</th>\n",
       "      <th>previous_seniority_director</th>\n",
       "      <th>previous_dept_administrative</th>\n",
       "      <th>previous_dept_business_dev</th>\n",
       "      <th>previous_dept_consulting</th>\n",
       "      <th>...</th>\n",
       "      <th>previous_dept_project_mgmt</th>\n",
       "      <th>previous_dept_purchasing</th>\n",
       "      <th>previous_dept_sales</th>\n",
       "      <th>same_department_as_previous</th>\n",
       "      <th>months_in_current_job</th>\n",
       "      <th>avg_job_duration</th>\n",
       "      <th>seniority_increases</th>\n",
       "      <th>department_changes</th>\n",
       "      <th>label</th>\n",
       "      <th>person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67.666667</td>\n",
       "      <td>44.991667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>409.566667</td>\n",
       "      <td>409.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Junior</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.866667</td>\n",
       "      <td>34.605556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Director</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.366667</td>\n",
       "      <td>28.807407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Senior</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45.366667</td>\n",
       "      <td>85.713333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Junior</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_jobs  job_number  previous_seniority_junior  \\\n",
       "0           8           1                          0   \n",
       "1           1           1                          0   \n",
       "2           6           1                          0   \n",
       "3           9           1                          0   \n",
       "4           5           1                          1   \n",
       "\n",
       "   previous_seniority_senior  previous_seniority_lead  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "\n",
       "   previous_seniority_management  previous_seniority_director  \\\n",
       "0                              0                            0   \n",
       "1                              0                            0   \n",
       "2                              0                            0   \n",
       "3                              0                            0   \n",
       "4                              0                            0   \n",
       "\n",
       "   previous_dept_administrative  previous_dept_business_dev  \\\n",
       "0                             0                           0   \n",
       "1                             0                           0   \n",
       "2                             0                           0   \n",
       "3                             0                           0   \n",
       "4                             1                           0   \n",
       "\n",
       "   previous_dept_consulting  ...  previous_dept_project_mgmt  \\\n",
       "0                         0  ...                           0   \n",
       "1                         0  ...                           0   \n",
       "2                         0  ...                           0   \n",
       "3                         0  ...                           0   \n",
       "4                         0  ...                           0   \n",
       "\n",
       "   previous_dept_purchasing  previous_dept_sales  same_department_as_previous  \\\n",
       "0                         0                    0                            0   \n",
       "1                         0                    0                            0   \n",
       "2                         0                    0                            0   \n",
       "3                         0                    0                            0   \n",
       "4                         0                    0                            1   \n",
       "\n",
       "   months_in_current_job  avg_job_duration  seniority_increases  \\\n",
       "0              67.666667         44.991667                    0   \n",
       "1             409.566667        409.566667                    0   \n",
       "2              14.866667         34.605556                    0   \n",
       "3              46.366667         28.807407                    0   \n",
       "4              45.366667         85.713333                    0   \n",
       "\n",
       "   department_changes     label  person_id  \n",
       "0                   0    Senior          0  \n",
       "1                   0    Junior          1  \n",
       "2                   0  Director          2  \n",
       "3                   0    Senior          3  \n",
       "4                   0    Junior          4  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_rf_training_frames(pseudo_persons, only_active=True):\n",
    "    rows_s, rows_d = [], []\n",
    "    for p_idx, person_jobs in enumerate(pseudo_persons):\n",
    "        for j_idx, job in enumerate(person_jobs):\n",
    "            if only_active and job.get(\"status\") != \"ACTIVE\":\n",
    "                continue\n",
    "            if job.get(\"seniority\") and job.get(\"department\"):\n",
    "                feats = extract_job_history_features(person_jobs, j_idx)\n",
    "                rs = dict(feats); rs[\"label\"] = str(job[\"seniority\"]); rs[\"person_id\"] = p_idx\n",
    "                rd = dict(feats); rd[\"label\"] = str(job[\"department\"]); rd[\"person_id\"] = p_idx\n",
    "                rows_s.append(rs); rows_d.append(rd)\n",
    "    return pd.DataFrame(rows_s), pd.DataFrame(rows_d)\n",
    "\n",
    "df_rf_sen, df_rf_dept = build_rf_training_frames(pseudo_filtered, only_active=pseudo_cfg.only_active)\n",
    "print(\"RF sen rows:\", len(df_rf_sen))\n",
    "print(\"RF dept rows:\", len(df_rf_dept))\n",
    "df_rf_sen.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1bdd7f",
   "metadata": {},
   "source": [
    "### 10) Optuna only for RF (on pseudo data, GroupSplit on person_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac68f4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 17:05:22,822] A new study created in memory with name: no-name-eeebbc6e-911a-42a9-a8b3-78c4965dcaa9\n",
      "[I 2026-01-21 17:05:23,147] Trial 0 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 300, 'max_depth': 26, 'min_samples_split': 17, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:23,479] Trial 1 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 12, 'max_features': None, 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:24,247] Trial 2 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 500, 'max_depth': 25, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:25,381] Trial 3 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 1100, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:26,966] Trial 4 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 1100, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:27,964] Trial 5 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 700, 'max_depth': 27, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:30,031] Trial 6 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 1100, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': None, 'bootstrap': True}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:31,166] Trial 7 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 600, 'max_depth': 16, 'min_samples_split': 11, 'min_samples_leaf': 12, 'max_features': None, 'bootstrap': True}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:33,169] Trial 8 finished with value: 0.12307692307692308 and parameters: {'n_estimators': 900, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:34,214] Trial 9 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 700, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:34,502] Trial 10 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 200, 'max_depth': 23, 'min_samples_split': 19, 'min_samples_leaf': 14, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:34,786] Trial 11 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:35,348] Trial 12 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 400, 'max_depth': 20, 'min_samples_split': 15, 'min_samples_leaf': 11, 'max_features': None, 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:35,917] Trial 13 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 400, 'max_depth': 29, 'min_samples_split': 8, 'min_samples_leaf': 15, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:36,387] Trial 14 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 300, 'max_depth': 12, 'min_samples_split': 14, 'min_samples_leaf': 13, 'max_features': None, 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:37,704] Trial 15 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 900, 'max_depth': 9, 'min_samples_split': 20, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:38,281] Trial 16 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 400, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:38,565] Trial 17 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 200, 'max_depth': 21, 'min_samples_split': 14, 'min_samples_leaf': 10, 'max_features': None, 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:39,214] Trial 18 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 500, 'max_depth': 14, 'min_samples_split': 17, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:40,379] Trial 19 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 900, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 13, 'max_features': None, 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:40,915] Trial 20 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 300, 'max_depth': 24, 'min_samples_split': 9, 'min_samples_leaf': 15, 'max_features': None, 'bootstrap': False}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:41,800] Trial 21 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 500, 'max_depth': 25, 'min_samples_split': 12, 'min_samples_leaf': 5, 'max_features': None, 'bootstrap': True}. Best is trial 0 with value: 0.14285714285714285.\n",
      "[I 2026-01-21 17:05:42,589] Trial 22 finished with value: 0.17424242424242425 and parameters: {'n_estimators': 500, 'max_depth': 26, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:43,063] Trial 23 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 300, 'max_depth': 27, 'min_samples_split': 17, 'min_samples_leaf': 9, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:43,898] Trial 24 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 600, 'max_depth': 21, 'min_samples_split': 13, 'min_samples_leaf': 12, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:44,364] Trial 25 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 300, 'max_depth': 28, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:44,979] Trial 26 finished with value: 0.17424242424242425 and parameters: {'n_estimators': 400, 'max_depth': 19, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:45,829] Trial 27 finished with value: 0.17424242424242425 and parameters: {'n_estimators': 600, 'max_depth': 19, 'min_samples_split': 16, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:46,966] Trial 28 finished with value: 0.17424242424242425 and parameters: {'n_estimators': 800, 'max_depth': 22, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:47,896] Trial 29 finished with value: 0.17424242424242425 and parameters: {'n_estimators': 600, 'max_depth': 18, 'min_samples_split': 18, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:49,009] Trial 30 finished with value: 0.17424242424242425 and parameters: {'n_estimators': 700, 'max_depth': 15, 'min_samples_split': 16, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:50,315] Trial 31 finished with value: 0.17424242424242425 and parameters: {'n_estimators': 800, 'max_depth': 22, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:51,563] Trial 32 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 800, 'max_depth': 20, 'min_samples_split': 15, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:52,346] Trial 33 finished with value: 0.17424242424242425 and parameters: {'n_estimators': 500, 'max_depth': 19, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:53,296] Trial 34 finished with value: 0.17424242424242425 and parameters: {'n_estimators': 600, 'max_depth': 23, 'min_samples_split': 19, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:54,610] Trial 35 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 800, 'max_depth': 26, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:56,265] Trial 36 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 1000, 'max_depth': 23, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:56,928] Trial 37 finished with value: 0.17424242424242425 and parameters: {'n_estimators': 400, 'max_depth': 17, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:57,915] Trial 38 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 600, 'max_depth': 25, 'min_samples_split': 16, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:05:59,787] Trial 39 finished with value: 0.17424242424242425 and parameters: {'n_estimators': 1200, 'max_depth': 12, 'min_samples_split': 18, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:06:00,778] Trial 40 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 700, 'max_depth': 19, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:06:01,713] Trial 41 finished with value: 0.17424242424242425 and parameters: {'n_estimators': 600, 'max_depth': 18, 'min_samples_split': 18, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:06:02,562] Trial 42 finished with value: 0.17424242424242425 and parameters: {'n_estimators': 500, 'max_depth': 16, 'min_samples_split': 18, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:06:03,611] Trial 43 finished with value: 0.17424242424242425 and parameters: {'n_estimators': 700, 'max_depth': 21, 'min_samples_split': 20, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:06:04,581] Trial 44 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 600, 'max_depth': 19, 'min_samples_split': 11, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:06:05,924] Trial 45 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 800, 'max_depth': 17, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:06:06,614] Trial 46 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 400, 'max_depth': 22, 'min_samples_split': 19, 'min_samples_leaf': 5, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:06:07,561] Trial 47 finished with value: 0.17424242424242425 and parameters: {'n_estimators': 500, 'max_depth': 15, 'min_samples_split': 17, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:06:08,591] Trial 48 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 600, 'max_depth': 24, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:06:09,568] Trial 49 finished with value: 0.14285714285714285 and parameters: {'n_estimators': 700, 'max_depth': 20, 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 22 with value: 0.17424242424242425.\n",
      "[I 2026-01-21 17:06:09,569] A new study created in memory with name: no-name-cd2fedc4-ade6-478e-9b75-1c7d4c069e5e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SEN params: {'n_estimators': 500, 'max_depth': 26, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}\n",
      "Best SEN macro-F1 (pseudo-val): 0.17424242424242425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 17:06:10,711] Trial 0 finished with value: 0.09722222222222221 and parameters: {'n_estimators': 1100, 'max_depth': 18, 'min_samples_split': 18, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': False}. Best is trial 0 with value: 0.09722222222222221.\n",
      "[I 2026-01-21 17:06:11,944] Trial 1 finished with value: 0.09523809523809523 and parameters: {'n_estimators': 800, 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 9, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.09722222222222221.\n",
      "[I 2026-01-21 17:06:12,396] Trial 2 finished with value: 0.09722222222222221 and parameters: {'n_estimators': 400, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.09722222222222221.\n",
      "[I 2026-01-21 17:06:13,645] Trial 3 finished with value: 0.09722222222222221 and parameters: {'n_estimators': 1200, 'max_depth': 19, 'min_samples_split': 12, 'min_samples_leaf': 12, 'max_features': None, 'bootstrap': False}. Best is trial 0 with value: 0.09722222222222221.\n",
      "[I 2026-01-21 17:06:14,601] Trial 4 finished with value: 0.09523809523809523 and parameters: {'n_estimators': 700, 'max_depth': 25, 'min_samples_split': 14, 'min_samples_leaf': 9, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.09722222222222221.\n",
      "[I 2026-01-21 17:06:15,511] Trial 5 finished with value: 0.05555555555555555 and parameters: {'n_estimators': 600, 'max_depth': 18, 'min_samples_split': 16, 'min_samples_leaf': 12, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.09722222222222221.\n",
      "[I 2026-01-21 17:06:16,580] Trial 6 finished with value: 0.09722222222222221 and parameters: {'n_estimators': 700, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.09722222222222221.\n",
      "[I 2026-01-21 17:06:17,814] Trial 7 finished with value: 0.09722222222222221 and parameters: {'n_estimators': 1100, 'max_depth': 15, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.09722222222222221.\n",
      "[I 2026-01-21 17:06:18,443] Trial 8 finished with value: 0.09523809523809523 and parameters: {'n_estimators': 400, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.09722222222222221.\n",
      "[I 2026-01-21 17:06:18,812] Trial 9 finished with value: 0.09722222222222221 and parameters: {'n_estimators': 300, 'max_depth': 19, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.09722222222222221.\n",
      "[I 2026-01-21 17:06:19,979] Trial 10 finished with value: 0.09722222222222221 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'min_samples_split': 19, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False}. Best is trial 0 with value: 0.09722222222222221.\n",
      "[I 2026-01-21 17:06:20,230] Trial 11 finished with value: 0.09722222222222221 and parameters: {'n_estimators': 200, 'max_depth': 26, 'min_samples_split': 18, 'min_samples_leaf': 15, 'max_features': None, 'bootstrap': False}. Best is trial 0 with value: 0.09722222222222221.\n",
      "[I 2026-01-21 17:06:20,777] Trial 12 finished with value: 0.10833333333333334 and parameters: {'n_estimators': 500, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False}. Best is trial 12 with value: 0.10833333333333334.\n",
      "[I 2026-01-21 17:06:21,781] Trial 13 finished with value: 0.15 and parameters: {'n_estimators': 900, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False}. Best is trial 13 with value: 0.15.\n",
      "[I 2026-01-21 17:06:22,774] Trial 14 finished with value: 0.15 and parameters: {'n_estimators': 900, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False}. Best is trial 13 with value: 0.15.\n",
      "[I 2026-01-21 17:06:23,747] Trial 15 finished with value: 0.15 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': False}. Best is trial 13 with value: 0.15.\n",
      "[I 2026-01-21 17:06:24,729] Trial 16 finished with value: 0.15 and parameters: {'n_estimators': 900, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': None, 'bootstrap': False}. Best is trial 13 with value: 0.15.\n",
      "[I 2026-01-21 17:06:25,711] Trial 17 finished with value: 0.15 and parameters: {'n_estimators': 900, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 13 with value: 0.15.\n",
      "[I 2026-01-21 17:06:26,562] Trial 18 finished with value: 0.09722222222222221 and parameters: {'n_estimators': 800, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': None, 'bootstrap': False}. Best is trial 13 with value: 0.15.\n",
      "[I 2026-01-21 17:06:27,912] Trial 19 finished with value: 0.07142857142857142 and parameters: {'n_estimators': 1200, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False}. Best is trial 13 with value: 0.15.\n",
      "[I 2026-01-21 17:06:28,986] Trial 20 finished with value: 0.15 and parameters: {'n_estimators': 1000, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': None, 'bootstrap': False}. Best is trial 13 with value: 0.15.\n",
      "[I 2026-01-21 17:06:29,984] Trial 21 finished with value: 0.15 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': False}. Best is trial 13 with value: 0.15.\n",
      "[I 2026-01-21 17:06:30,914] Trial 22 finished with value: 0.15 and parameters: {'n_estimators': 800, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': False}. Best is trial 13 with value: 0.15.\n",
      "[I 2026-01-21 17:06:32,108] Trial 23 finished with value: 0.15 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': False}. Best is trial 13 with value: 0.15.\n",
      "[I 2026-01-21 17:06:32,813] Trial 24 finished with value: 0.15 and parameters: {'n_estimators': 600, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': False}. Best is trial 13 with value: 0.15.\n",
      "[I 2026-01-21 17:06:33,561] Trial 25 finished with value: 0.10833333333333334 and parameters: {'n_estimators': 700, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 13 with value: 0.15.\n",
      "[I 2026-01-21 17:06:35,085] Trial 26 finished with value: 0.16666666666666666 and parameters: {'n_estimators': 1100, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:36,761] Trial 27 finished with value: 0.09722222222222221 and parameters: {'n_estimators': 1100, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:38,311] Trial 28 finished with value: 0.05555555555555555 and parameters: {'n_estimators': 1000, 'max_depth': 14, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:40,429] Trial 29 finished with value: 0.05555555555555555 and parameters: {'n_estimators': 1100, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:42,296] Trial 30 finished with value: 0.09523809523809523 and parameters: {'n_estimators': 1200, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:43,296] Trial 31 finished with value: 0.15 and parameters: {'n_estimators': 900, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': False}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:44,427] Trial 32 finished with value: 0.08333333333333333 and parameters: {'n_estimators': 800, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:45,497] Trial 33 finished with value: 0.15 and parameters: {'n_estimators': 1000, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': False}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:46,980] Trial 34 finished with value: 0.16666666666666666 and parameters: {'n_estimators': 1100, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:48,505] Trial 35 finished with value: 0.09523809523809523 and parameters: {'n_estimators': 1100, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:50,298] Trial 36 finished with value: 0.06666666666666667 and parameters: {'n_estimators': 1200, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:51,795] Trial 37 finished with value: 0.09722222222222221 and parameters: {'n_estimators': 1100, 'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 11, 'max_features': 'log2', 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:53,336] Trial 38 finished with value: 0.16666666666666666 and parameters: {'n_estimators': 1100, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:54,960] Trial 39 finished with value: 0.09722222222222221 and parameters: {'n_estimators': 1200, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:56,263] Trial 40 finished with value: 0.05555555555555555 and parameters: {'n_estimators': 1000, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 15, 'max_features': 'log2', 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:57,712] Trial 41 finished with value: 0.16666666666666666 and parameters: {'n_estimators': 1100, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:06:59,180] Trial 42 finished with value: 0.16666666666666666 and parameters: {'n_estimators': 1100, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:07:00,697] Trial 43 finished with value: 0.16666666666666666 and parameters: {'n_estimators': 1100, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:07:02,163] Trial 44 finished with value: 0.16666666666666666 and parameters: {'n_estimators': 1100, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:07:03,724] Trial 45 finished with value: 0.06666666666666667 and parameters: {'n_estimators': 1200, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:07:05,179] Trial 46 finished with value: 0.15 and parameters: {'n_estimators': 1100, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:07:06,740] Trial 47 finished with value: 0.09722222222222221 and parameters: {'n_estimators': 1200, 'max_depth': 14, 'min_samples_split': 13, 'min_samples_leaf': 10, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:07:08,286] Trial 48 finished with value: 0.05555555555555555 and parameters: {'n_estimators': 1000, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n",
      "[I 2026-01-21 17:07:09,811] Trial 49 finished with value: 0.16666666666666666 and parameters: {'n_estimators': 1100, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': True}. Best is trial 26 with value: 0.16666666666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best DEPT params: {'n_estimators': 1100, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}\n",
      "Best DEPT macro-F1 (pseudo-val): 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "def make_rf_objective_from_df(df_rf: pd.DataFrame, seed=42):\n",
    "    if len(df_rf) == 0:\n",
    "        raise RuntimeError(\"df_rf leer. Check thresholds / filtering.\")\n",
    "\n",
    "    X = df_rf[FEATURE_COLS].fillna(0)\n",
    "    y = df_rf[\"label\"].astype(str).values\n",
    "    groups = df_rf[\"person_id\"].values\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "\n",
    "    idxs = np.arange(len(df_rf))\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "    tr_idx, va_idx = next(gss.split(idxs, groups=groups))\n",
    "\n",
    "    X_train, X_val = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    y_train, y_val = y_enc[tr_idx], y_enc[va_idx]\n",
    "\n",
    "    def objective(trial: optuna.Trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1200, step=100),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 4, 30),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 15),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None]),\n",
    "            \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "            \"random_state\": seed,\n",
    "            \"n_jobs\": -1,\n",
    "        }\n",
    "\n",
    "        rf = RandomForestClassifier(**params)\n",
    "        rf.fit(X_train, y_train)\n",
    "        pred = rf.predict(X_val)\n",
    "        return f1_score(y_val, pred, average=\"macro\")\n",
    "\n",
    "    return objective\n",
    "\n",
    "# Seniority tuning\n",
    "study_sen = optuna.create_study(direction=\"maximize\")\n",
    "study_sen.optimize(make_rf_objective_from_df(df_rf_sen, seed=train_cfg.random_state), n_trials=50)\n",
    "print(\"Best SEN params:\", study_sen.best_params)\n",
    "print(\"Best SEN macro-F1 (pseudo-val):\", study_sen.best_value)\n",
    "\n",
    "# Department tuning\n",
    "study_dept = optuna.create_study(direction=\"maximize\")\n",
    "study_dept.optimize(make_rf_objective_from_df(df_rf_dept, seed=train_cfg.random_state), n_trials=50)\n",
    "print(\"Best DEPT params:\", study_dept.best_params)\n",
    "print(\"Best DEPT macro-F1 (pseudo-val):\", study_dept.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f5875f",
   "metadata": {},
   "source": [
    "### 11) Final RF training (with best params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3ab35df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFs trained on full pseudo data.\n"
     ]
    }
   ],
   "source": [
    "def train_rf_with_params(df_rf: pd.DataFrame, best_params: Dict[str, Any], seed=42):\n",
    "    X = df_rf[FEATURE_COLS].fillna(0)\n",
    "    y = df_rf[\"label\"].astype(str)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "\n",
    "    params = dict(best_params)\n",
    "    params.update({\"random_state\": seed, \"n_jobs\": -1})\n",
    "\n",
    "    rf = RandomForestClassifier(**params)\n",
    "    rf.fit(X, y_enc)\n",
    "    return rf, le\n",
    "\n",
    "rf_sen, le_sen_rf = train_rf_with_params(df_rf_sen, study_sen.best_params, seed=train_cfg.random_state)\n",
    "rf_dept, le_dept_rf = train_rf_with_params(df_rf_dept, study_dept.best_params, seed=train_cfg.random_state)\n",
    "\n",
    "print(\"RFs trained on full pseudo data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d996d9f5",
   "metadata": {},
   "source": [
    "### 12) Hybrid Predictor (Baseline vs RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a386aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridPredictorBaseRF:\n",
    "    def __init__(self, baseline_model: Pipeline, rf_model: RandomForestClassifier, le_rf: LabelEncoder,\n",
    "                 is_department: bool, cfg: HybridConfig):\n",
    "        self.baseline_model = baseline_model\n",
    "        self.rf_model = rf_model\n",
    "        self.le_rf = le_rf\n",
    "        self.is_department = is_department\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def predict(self, person_jobs: List[Dict[str, Any]], target_job_idx: int = 0) -> str:\n",
    "        job = person_jobs[target_job_idx]\n",
    "        text = str(job.get(\"position\",\"\")).strip()\n",
    "\n",
    "        base_label, base_conf = baseline_predict_label_conf(self.baseline_model, text)\n",
    "\n",
    "        feats = extract_job_history_features(person_jobs, target_job_idx)\n",
    "        X = pd.DataFrame([feats])[FEATURE_COLS].fillna(0)\n",
    "        rf_idx = int(self.rf_model.predict(X)[0])\n",
    "        rf_probs = self.rf_model.predict_proba(X)[0]\n",
    "        rf_conf = float(np.max(rf_probs))\n",
    "        rf_label = str(self.le_rf.inverse_transform([rf_idx])[0])\n",
    "\n",
    "        if base_conf >= self.cfg.base_hi:\n",
    "            return base_label\n",
    "        if rf_conf >= self.cfg.rf_hi:\n",
    "            return rf_label\n",
    "\n",
    "        if self.is_department and self.cfg.dept_fallback and base_conf < 0.6 and rf_conf < 0.6:\n",
    "            if len(person_jobs) > target_job_idx + 1:\n",
    "                prev = person_jobs[target_job_idx + 1]\n",
    "                prev_dept = prev.get(\"department\")\n",
    "                if prev_dept:\n",
    "                    return str(prev_dept)\n",
    "\n",
    "        return base_label if base_conf >= rf_conf else rf_label\n",
    "\n",
    "hybrid_sen = HybridPredictorBaseRF(sen_baseline, rf_sen, le_sen_rf, is_department=False, cfg=hybrid_cfg)\n",
    "hybrid_dept = HybridPredictorBaseRF(dept_baseline, rf_dept, le_dept_rf, is_department=True, cfg=hybrid_cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367da54",
   "metadata": {},
   "source": [
    "### 13) Hybrid Evaluation on annotated (Original + Fair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db4c0426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ANSATZ 6 + 5 (Hybrid) — ORIGINAL\n",
      "======================================================================\n",
      "\n",
      "SENIORITY (original)\n",
      "Accuracy: 0.42857142857142855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Director       0.50      0.97      0.66        34\n",
      "      Junior       0.24      0.33      0.28        12\n",
      "        Lead       0.88      0.55      0.68       125\n",
      "  Management       0.94      0.62      0.75       192\n",
      "Professional       0.00      0.00      0.00       216\n",
      "      Senior       0.12      0.95      0.22        44\n",
      "\n",
      "    accuracy                           0.43       623\n",
      "   macro avg       0.45      0.57      0.43       623\n",
      "weighted avg       0.51      0.43      0.42       623\n",
      "\n",
      "\n",
      "DEPARTMENT (original)\n",
      "Accuracy: 0.5698234349919743\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        Administrative       0.36      0.36      0.36        14\n",
      "  Business Development       0.21      0.35      0.26        20\n",
      "            Consulting       0.40      0.46      0.43        39\n",
      "      Customer Support       0.43      0.50      0.46         6\n",
      "       Human Resources       0.58      0.69      0.63        16\n",
      "Information Technology       0.47      0.63      0.54        62\n",
      "             Marketing       0.38      0.50      0.43        22\n",
      "                 Other       0.78      0.55      0.64       344\n",
      "    Project Management       0.54      0.69      0.61        39\n",
      "            Purchasing       0.87      0.87      0.87        15\n",
      "                 Sales       0.39      0.72      0.50        46\n",
      "\n",
      "              accuracy                           0.57       623\n",
      "             macro avg       0.49      0.57      0.52       623\n",
      "          weighted avg       0.63      0.57      0.58       623\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ANSATZ 6 + 5 (Hybrid) — FAIR\n",
      "======================================================================\n",
      "\n",
      "SENIORITY (fair): Professional korrekt, wenn Junior oder Senior vorhergesagt\n",
      "Accuracy: 0.7480\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Director       0.50      0.97      0.66        34\n",
      "      Junior       0.57      0.33      0.42        12\n",
      "        Lead       0.88      0.55      0.68       125\n",
      "  Management       0.94      0.62      0.75       192\n",
      "Professional       1.00      0.92      0.96       216\n",
      "      Senior       0.29      0.95      0.44        44\n",
      "\n",
      "    accuracy                           0.75       623\n",
      "   macro avg       0.70      0.73      0.65       623\n",
      "weighted avg       0.87      0.75      0.77       623\n",
      "\n",
      "\n",
      "DEPARTMENT (fair): 'Other' ausgeschlossen\n",
      "Evaluiert auf 279/623 Jobs\n",
      "Accuracy: 0.5986\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        Administrative       0.50      0.36      0.42        14\n",
      "  Business Development       0.50      0.35      0.41        20\n",
      "            Consulting       0.64      0.46      0.54        39\n",
      "      Customer Support       0.60      0.50      0.55         6\n",
      "       Human Resources       0.79      0.69      0.73        16\n",
      "Information Technology       0.85      0.63      0.72        62\n",
      "             Marketing       0.58      0.50      0.54        22\n",
      "                 Other       0.00      0.00      0.00         0\n",
      "    Project Management       0.82      0.69      0.75        39\n",
      "            Purchasing       0.87      0.87      0.87        15\n",
      "                 Sales       0.80      0.72      0.76        46\n",
      "\n",
      "              accuracy                           0.60       279\n",
      "             macro avg       0.63      0.52      0.57       279\n",
      "          weighted avg       0.74      0.60      0.66       279\n",
      "\n",
      "\n",
      "======================================================================\n",
      "VERGLEICH: Original vs Fair\n",
      "======================================================================\n",
      "             Metric  Original     Fair\n",
      " Seniority Accuracy  0.428571 0.747994\n",
      "Department Accuracy  0.569823 0.598566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haqu0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\haqu0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\haqu0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\haqu0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\haqu0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\haqu0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7479935794542536, 0.5985663082437276)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sen_h, pred_dept_h = [], []\n",
    "true_sen_h, true_dept_h = [], []\n",
    "\n",
    "for person_jobs in annotated:\n",
    "    for idx, job in enumerate(person_jobs):\n",
    "        if job.get(\"status\") != \"ACTIVE\":\n",
    "            continue\n",
    "        if job.get(\"seniority\") is None or job.get(\"department\") is None:\n",
    "            continue\n",
    "\n",
    "        true_sen_h.append(str(job[\"seniority\"]))\n",
    "        true_dept_h.append(str(job[\"department\"]))\n",
    "\n",
    "        pred_sen_h.append(hybrid_sen.predict(person_jobs, idx))\n",
    "        pred_dept_h.append(hybrid_dept.predict(person_jobs, idx))\n",
    "\n",
    "evaluate_original(true_sen_h, pred_sen_h, true_dept_h, pred_dept_h, title=\"ANSATZ 6 + 5 (Hybrid) — ORIGINAL\")\n",
    "fair_evaluation(true_sen_h, pred_sen_h, true_dept_h, pred_dept_h, title=\"ANSATZ 6 + 5 (Hybrid) — FAIR\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45fe83d",
   "metadata": {},
   "source": [
    "# Save all models for streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afef592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models saved to: saved_models\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "MODEL_DIR = \"saved_models\"\n",
    "import os\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Save Baseline Models\n",
    "# ---------------------------\n",
    "joblib.dump(sen_baseline, f\"{MODEL_DIR}/sen_baseline_tfidf_lr.joblib\")\n",
    "joblib.dump(dept_baseline, f\"{MODEL_DIR}/dept_baseline_tfidf_lr.joblib\")\n",
    "\n",
    "# ---------------------------\n",
    "# Save RF Models + Encoders\n",
    "# ---------------------------\n",
    "joblib.dump(rf_sen, f\"{MODEL_DIR}/rf_seniority.joblib\")\n",
    "joblib.dump(rf_dept, f\"{MODEL_DIR}/rf_department.joblib\")\n",
    "\n",
    "joblib.dump(le_sen_rf, f\"{MODEL_DIR}/le_seniority.joblib\")\n",
    "joblib.dump(le_dept_rf, f\"{MODEL_DIR}/le_department.joblib\")\n",
    "\n",
    "# ---------------------------\n",
    "# Save Configs \n",
    "# ---------------------------\n",
    "joblib.dump(hybrid_cfg, f\"{MODEL_DIR}/hybrid_cfg.joblib\")\n",
    "joblib.dump(pseudo_cfg, f\"{MODEL_DIR}/pseudo_cfg.joblib\")\n",
    "\n",
    "print(\"✅ Models saved to:\", MODEL_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
